{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
    "# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it in to inspect it\n",
    "with open('./data/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's look at the first 1000 characters\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '$',\n",
       " '&',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '3',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '$': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " '3': 9,\n",
       " ':': 10,\n",
       " ';': 11,\n",
       " '?': 12,\n",
       " 'A': 13,\n",
       " 'B': 14,\n",
       " 'C': 15,\n",
       " 'D': 16,\n",
       " 'E': 17,\n",
       " 'F': 18,\n",
       " 'G': 19,\n",
       " 'H': 20,\n",
       " 'I': 21,\n",
       " 'J': 22,\n",
       " 'K': 23,\n",
       " 'L': 24,\n",
       " 'M': 25,\n",
       " 'N': 26,\n",
       " 'O': 27,\n",
       " 'P': 28,\n",
       " 'Q': 29,\n",
       " 'R': 30,\n",
       " 'S': 31,\n",
       " 'T': 32,\n",
       " 'U': 33,\n",
       " 'V': 34,\n",
       " 'W': 35,\n",
       " 'X': 36,\n",
       " 'Y': 37,\n",
       " 'Z': 38,\n",
       " 'a': 39,\n",
       " 'b': 40,\n",
       " 'c': 41,\n",
       " 'd': 42,\n",
       " 'e': 43,\n",
       " 'f': 44,\n",
       " 'g': 45,\n",
       " 'h': 46,\n",
       " 'i': 47,\n",
       " 'j': 48,\n",
       " 'k': 49,\n",
       " 'l': 50,\n",
       " 'm': 51,\n",
       " 'n': 52,\n",
       " 'o': 53,\n",
       " 'p': 54,\n",
       " 'q': 55,\n",
       " 'r': 56,\n",
       " 's': 57,\n",
       " 't': 58,\n",
       " 'u': 59,\n",
       " 'v': 60,\n",
       " 'w': 61,\n",
       " 'x': 62,\n",
       " 'y': 63,\n",
       " 'z': 64}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '$': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " '3': 9,\n",
       " ':': 10,\n",
       " ';': 11,\n",
       " '?': 12,\n",
       " 'A': 13,\n",
       " 'B': 14,\n",
       " 'C': 15,\n",
       " 'D': 16,\n",
       " 'E': 17,\n",
       " 'F': 18,\n",
       " 'G': 19,\n",
       " 'H': 20,\n",
       " 'I': 21,\n",
       " 'J': 22,\n",
       " 'K': 23,\n",
       " 'L': 24,\n",
       " 'M': 25,\n",
       " 'N': 26,\n",
       " 'O': 27,\n",
       " 'P': 28,\n",
       " 'Q': 29,\n",
       " 'R': 30,\n",
       " 'S': 31,\n",
       " 'T': 32,\n",
       " 'U': 33,\n",
       " 'V': 34,\n",
       " 'W': 35,\n",
       " 'X': 36,\n",
       " 'Y': 37,\n",
       " 'Z': 38,\n",
       " 'a': 39,\n",
       " 'b': 40,\n",
       " 'c': 41,\n",
       " 'd': 42,\n",
       " 'e': 43,\n",
       " 'f': 44,\n",
       " 'g': 45,\n",
       " 'h': 46,\n",
       " 'i': 47,\n",
       " 'j': 48,\n",
       " 'k': 49,\n",
       " 'l': 50,\n",
       " 'm': 51,\n",
       " 'n': 52,\n",
       " 'o': 53,\n",
       " 'p': 54,\n",
       " 'q': 55,\n",
       " 'r': 56,\n",
       " 's': 57,\n",
       " 't': 58,\n",
       " 'u': 59,\n",
       " 'v': 60,\n",
       " 'w': 61,\n",
       " 'x': 62,\n",
       " 'y': 63,\n",
       " 'z': 64}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = { i:ch for i,ch in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '\\n',\n",
       " 1: ' ',\n",
       " 2: '!',\n",
       " 3: '$',\n",
       " 4: '&',\n",
       " 5: \"'\",\n",
       " 6: ',',\n",
       " 7: '-',\n",
       " 8: '.',\n",
       " 9: '3',\n",
       " 10: ':',\n",
       " 11: ';',\n",
       " 12: '?',\n",
       " 13: 'A',\n",
       " 14: 'B',\n",
       " 15: 'C',\n",
       " 16: 'D',\n",
       " 17: 'E',\n",
       " 18: 'F',\n",
       " 19: 'G',\n",
       " 20: 'H',\n",
       " 21: 'I',\n",
       " 22: 'J',\n",
       " 23: 'K',\n",
       " 24: 'L',\n",
       " 25: 'M',\n",
       " 26: 'N',\n",
       " 27: 'O',\n",
       " 28: 'P',\n",
       " 29: 'Q',\n",
       " 30: 'R',\n",
       " 31: 'S',\n",
       " 32: 'T',\n",
       " 33: 'U',\n",
       " 34: 'V',\n",
       " 35: 'W',\n",
       " 36: 'X',\n",
       " 37: 'Y',\n",
       " 38: 'Z',\n",
       " 39: 'a',\n",
       " 40: 'b',\n",
       " 41: 'c',\n",
       " 42: 'd',\n",
       " 43: 'e',\n",
       " 44: 'f',\n",
       " 45: 'g',\n",
       " 46: 'h',\n",
       " 47: 'i',\n",
       " 48: 'j',\n",
       " 49: 'k',\n",
       " 50: 'l',\n",
       " 51: 'm',\n",
       " 52: 'n',\n",
       " 53: 'o',\n",
       " 54: 'p',\n",
       " 55: 'q',\n",
       " 56: 'r',\n",
       " 57: 's',\n",
       " 58: 't',\n",
       " 59: 'u',\n",
       " 60: 'v',\n",
       " 61: 'w',\n",
       " 62: 'x',\n",
       " 63: 'y',\n",
       " 64: 'z'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 1, 58, 46, 43, 56, 43, 2]\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"hi there!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi there!\n"
     ]
    }
   ],
   "source": [
    "print(decode([46, 47, 1, 58, 46, 43, 56, 43, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi there!\n"
     ]
    }
   ],
   "source": [
    "print(decode(encode(\"hi there!\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
    "import torch # we use PyTorch: https://pytorch.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1+cpu'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AVG',\n",
       " 'AggregationType',\n",
       " 'AliasDb',\n",
       " 'Any',\n",
       " 'AnyType',\n",
       " 'Argument',\n",
       " 'ArgumentSpec',\n",
       " 'AwaitType',\n",
       " 'BFloat16Storage',\n",
       " 'BFloat16Tensor',\n",
       " 'BenchmarkConfig',\n",
       " 'BenchmarkExecutionStats',\n",
       " 'Block',\n",
       " 'BoolStorage',\n",
       " 'BoolTensor',\n",
       " 'BoolType',\n",
       " 'BufferDict',\n",
       " 'ByteStorage',\n",
       " 'ByteTensor',\n",
       " 'CallStack',\n",
       " 'Callable',\n",
       " 'Capsule',\n",
       " 'CharStorage',\n",
       " 'CharTensor',\n",
       " 'ClassType',\n",
       " 'Code',\n",
       " 'CompilationUnit',\n",
       " 'CompleteArgumentSpec',\n",
       " 'ComplexDoubleStorage',\n",
       " 'ComplexFloatStorage',\n",
       " 'ComplexType',\n",
       " 'ConcreteModuleType',\n",
       " 'ConcreteModuleTypeBuilder',\n",
       " 'DeepCopyMemoTable',\n",
       " 'DeserializationStorageContext',\n",
       " 'DeviceObjType',\n",
       " 'Dict',\n",
       " 'DictType',\n",
       " 'DisableTorchFunction',\n",
       " 'DisableTorchFunctionSubclass',\n",
       " 'DispatchKey',\n",
       " 'DispatchKeySet',\n",
       " 'DoubleStorage',\n",
       " 'DoubleTensor',\n",
       " 'EnumType',\n",
       " 'ErrorReport',\n",
       " 'Event',\n",
       " 'ExcludeDispatchKeyGuard',\n",
       " 'ExecutionPlan',\n",
       " 'FatalError',\n",
       " 'FileCheck',\n",
       " 'FloatStorage',\n",
       " 'FloatTensor',\n",
       " 'FloatType',\n",
       " 'FunctionSchema',\n",
       " 'Future',\n",
       " 'FutureType',\n",
       " 'Generator',\n",
       " 'GradScaler',\n",
       " 'Gradient',\n",
       " 'Graph',\n",
       " 'GraphExecutorState',\n",
       " 'HalfStorage',\n",
       " 'HalfTensor',\n",
       " 'IODescriptor',\n",
       " 'InferredType',\n",
       " 'IntStorage',\n",
       " 'IntTensor',\n",
       " 'IntType',\n",
       " 'InterfaceType',\n",
       " 'JITException',\n",
       " 'List',\n",
       " 'ListType',\n",
       " 'LiteScriptModule',\n",
       " 'LockingLogger',\n",
       " 'LoggerBase',\n",
       " 'LongStorage',\n",
       " 'LongTensor',\n",
       " 'ModuleDict',\n",
       " 'Node',\n",
       " 'NoneType',\n",
       " 'NoopLogger',\n",
       " 'NumberType',\n",
       " 'OperatorInfo',\n",
       " 'Optional',\n",
       " 'OptionalType',\n",
       " 'OutOfMemoryError',\n",
       " 'PRIVATE_OPS',\n",
       " 'ParameterDict',\n",
       " 'PyObjectType',\n",
       " 'PyTorchFileReader',\n",
       " 'PyTorchFileWriter',\n",
       " 'QInt32Storage',\n",
       " 'QInt8Storage',\n",
       " 'QUInt2x4Storage',\n",
       " 'QUInt4x2Storage',\n",
       " 'QUInt8Storage',\n",
       " 'RRefType',\n",
       " 'SUM',\n",
       " 'ScriptClass',\n",
       " 'ScriptClassFunction',\n",
       " 'ScriptDict',\n",
       " 'ScriptDictIterator',\n",
       " 'ScriptDictKeyIterator',\n",
       " 'ScriptFunction',\n",
       " 'ScriptList',\n",
       " 'ScriptListIterator',\n",
       " 'ScriptMethod',\n",
       " 'ScriptModule',\n",
       " 'ScriptModuleSerializer',\n",
       " 'ScriptObject',\n",
       " 'ScriptObjectProperty',\n",
       " 'SerializationStorageContext',\n",
       " 'Set',\n",
       " 'ShortStorage',\n",
       " 'ShortTensor',\n",
       " 'Size',\n",
       " 'StaticModule',\n",
       " 'Storage',\n",
       " 'StorageBase',\n",
       " 'Stream',\n",
       " 'StreamObjType',\n",
       " 'StringType',\n",
       " 'SymBool',\n",
       " 'SymBoolType',\n",
       " 'SymFloat',\n",
       " 'SymInt',\n",
       " 'SymIntType',\n",
       " 'TYPE_CHECKING',\n",
       " 'Tag',\n",
       " 'Tensor',\n",
       " 'TensorType',\n",
       " 'ThroughputBenchmark',\n",
       " 'TracingState',\n",
       " 'Tuple',\n",
       " 'TupleType',\n",
       " 'Type',\n",
       " 'TypedStorage',\n",
       " 'USE_GLOBAL_DEPS',\n",
       " 'USE_RTLD_GLOBAL_WITH_LIBTORCH',\n",
       " 'Union',\n",
       " 'UnionType',\n",
       " 'UntypedStorage',\n",
       " 'Use',\n",
       " 'Value',\n",
       " '_C',\n",
       " '_GLOBAL_DEVICE_CONTEXT',\n",
       " '_TorchCompileInductorWrapper',\n",
       " '_TorchCompileWrapper',\n",
       " '_TritonLibrary',\n",
       " '_VF',\n",
       " '__all__',\n",
       " '__annotations__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__config__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__future__',\n",
       " '__getattr__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_adaptive_avg_pool2d',\n",
       " '_adaptive_avg_pool3d',\n",
       " '_add_batch_dim',\n",
       " '_add_relu',\n",
       " '_add_relu_',\n",
       " '_addmm_activation',\n",
       " '_aminmax',\n",
       " '_amp_foreach_non_finite_check_and_unscale_',\n",
       " '_amp_update_scale_',\n",
       " '_assert',\n",
       " '_assert_async',\n",
       " '_assert_scalar',\n",
       " '_assert_tensor_metadata',\n",
       " '_awaits',\n",
       " '_batch_norm_impl_index',\n",
       " '_cast_Byte',\n",
       " '_cast_Char',\n",
       " '_cast_Double',\n",
       " '_cast_Float',\n",
       " '_cast_Half',\n",
       " '_cast_Int',\n",
       " '_cast_Long',\n",
       " '_cast_Short',\n",
       " '_check',\n",
       " '_check_index',\n",
       " '_check_is_size',\n",
       " '_check_not_implemented',\n",
       " '_check_tensor_all',\n",
       " '_check_tensor_all_with',\n",
       " '_check_type',\n",
       " '_check_value',\n",
       " '_check_with',\n",
       " '_choose_qparams_per_tensor',\n",
       " '_chunk_cat',\n",
       " '_classes',\n",
       " '_coalesce',\n",
       " '_compile',\n",
       " '_compute_linear_combination',\n",
       " '_conj',\n",
       " '_conj_copy',\n",
       " '_conj_physical',\n",
       " '_constrain_as_size',\n",
       " '_convert_indices_from_coo_to_csr',\n",
       " '_convert_indices_from_csr_to_coo',\n",
       " '_convert_weight_to_int4pack',\n",
       " '_convolution',\n",
       " '_convolution_mode',\n",
       " '_copy_from',\n",
       " '_copy_from_and_resize',\n",
       " '_cslt_compress',\n",
       " '_cslt_sparse_mm',\n",
       " '_cslt_sparse_mm_search',\n",
       " '_ctc_loss',\n",
       " '_cudnn_ctc_loss',\n",
       " '_cudnn_init_dropout_state',\n",
       " '_cudnn_rnn',\n",
       " '_cudnn_rnn_flatten_weight',\n",
       " '_cufft_clear_plan_cache',\n",
       " '_cufft_get_plan_cache_max_size',\n",
       " '_cufft_get_plan_cache_size',\n",
       " '_cufft_set_plan_cache_max_size',\n",
       " '_cummax_helper',\n",
       " '_cummin_helper',\n",
       " '_custom_op',\n",
       " '_debug_has_internal_overlap',\n",
       " '_decomp',\n",
       " '_deprecated_attrs',\n",
       " '_dim_arange',\n",
       " '_dirichlet_grad',\n",
       " '_disable_dynamo',\n",
       " '_disable_functionalization',\n",
       " '_dispatch',\n",
       " '_efficientzerotensor',\n",
       " '_embedding_bag',\n",
       " '_embedding_bag_forward_only',\n",
       " '_empty_affine_quantized',\n",
       " '_empty_per_channel_affine_quantized',\n",
       " '_enable_functionalization',\n",
       " '_euclidean_dist',\n",
       " '_fake_quantize_learnable_per_channel_affine',\n",
       " '_fake_quantize_learnable_per_tensor_affine',\n",
       " '_fake_quantize_per_tensor_affine_cachemask_tensor_qparams',\n",
       " '_fft_c2c',\n",
       " '_fft_c2r',\n",
       " '_fft_r2c',\n",
       " '_fill_mem_eff_dropout_mask_',\n",
       " '_foobar',\n",
       " '_foreach_abs',\n",
       " '_foreach_abs_',\n",
       " '_foreach_acos',\n",
       " '_foreach_acos_',\n",
       " '_foreach_add',\n",
       " '_foreach_add_',\n",
       " '_foreach_addcdiv',\n",
       " '_foreach_addcdiv_',\n",
       " '_foreach_addcmul',\n",
       " '_foreach_addcmul_',\n",
       " '_foreach_asin',\n",
       " '_foreach_asin_',\n",
       " '_foreach_atan',\n",
       " '_foreach_atan_',\n",
       " '_foreach_ceil',\n",
       " '_foreach_ceil_',\n",
       " '_foreach_clamp_max',\n",
       " '_foreach_clamp_max_',\n",
       " '_foreach_clamp_min',\n",
       " '_foreach_clamp_min_',\n",
       " '_foreach_copy_',\n",
       " '_foreach_cos',\n",
       " '_foreach_cos_',\n",
       " '_foreach_cosh',\n",
       " '_foreach_cosh_',\n",
       " '_foreach_div',\n",
       " '_foreach_div_',\n",
       " '_foreach_erf',\n",
       " '_foreach_erf_',\n",
       " '_foreach_erfc',\n",
       " '_foreach_erfc_',\n",
       " '_foreach_exp',\n",
       " '_foreach_exp_',\n",
       " '_foreach_expm1',\n",
       " '_foreach_expm1_',\n",
       " '_foreach_floor',\n",
       " '_foreach_floor_',\n",
       " '_foreach_frac',\n",
       " '_foreach_frac_',\n",
       " '_foreach_lerp',\n",
       " '_foreach_lerp_',\n",
       " '_foreach_lgamma',\n",
       " '_foreach_lgamma_',\n",
       " '_foreach_log',\n",
       " '_foreach_log10',\n",
       " '_foreach_log10_',\n",
       " '_foreach_log1p',\n",
       " '_foreach_log1p_',\n",
       " '_foreach_log2',\n",
       " '_foreach_log2_',\n",
       " '_foreach_log_',\n",
       " '_foreach_max',\n",
       " '_foreach_maximum',\n",
       " '_foreach_maximum_',\n",
       " '_foreach_minimum',\n",
       " '_foreach_minimum_',\n",
       " '_foreach_mul',\n",
       " '_foreach_mul_',\n",
       " '_foreach_neg',\n",
       " '_foreach_neg_',\n",
       " '_foreach_norm',\n",
       " '_foreach_pow',\n",
       " '_foreach_pow_',\n",
       " '_foreach_reciprocal',\n",
       " '_foreach_reciprocal_',\n",
       " '_foreach_round',\n",
       " '_foreach_round_',\n",
       " '_foreach_sigmoid',\n",
       " '_foreach_sigmoid_',\n",
       " '_foreach_sign',\n",
       " '_foreach_sign_',\n",
       " '_foreach_sin',\n",
       " '_foreach_sin_',\n",
       " '_foreach_sinh',\n",
       " '_foreach_sinh_',\n",
       " '_foreach_sqrt',\n",
       " '_foreach_sqrt_',\n",
       " '_foreach_sub',\n",
       " '_foreach_sub_',\n",
       " '_foreach_tan',\n",
       " '_foreach_tan_',\n",
       " '_foreach_tanh',\n",
       " '_foreach_tanh_',\n",
       " '_foreach_trunc',\n",
       " '_foreach_trunc_',\n",
       " '_foreach_zero_',\n",
       " '_freeze_functional_tensor',\n",
       " '_from_functional_tensor',\n",
       " '_functional_assert_async',\n",
       " '_functional_assert_scalar',\n",
       " '_functional_sym_constrain_range',\n",
       " '_functional_sym_constrain_range_for_size',\n",
       " '_functionalize_apply_view_metas',\n",
       " '_functionalize_are_all_mutations_hidden_from_autograd',\n",
       " '_functionalize_are_all_mutations_under_no_grad_or_inference_mode',\n",
       " '_functionalize_commit_update',\n",
       " '_functionalize_enable_reapply_views',\n",
       " '_functionalize_get_storage_size',\n",
       " '_functionalize_has_data_mutation',\n",
       " '_functionalize_has_metadata_mutation',\n",
       " '_functionalize_is_multi_output_view',\n",
       " '_functionalize_is_symbolic',\n",
       " '_functionalize_mark_mutation_hidden_from_autograd',\n",
       " '_functionalize_replace',\n",
       " '_functionalize_sync',\n",
       " '_functionalize_was_inductor_storage_resized',\n",
       " '_functionalize_was_storage_changed',\n",
       " '_functorch',\n",
       " '_fused_adagrad_',\n",
       " '_fused_adam_',\n",
       " '_fused_adamw_',\n",
       " '_fused_dropout',\n",
       " '_fused_moving_avg_obs_fq_helper',\n",
       " '_fused_sdp_choice',\n",
       " '_fused_sgd_',\n",
       " '_fw_primal_copy',\n",
       " '_grid_sampler_2d_cpu_fallback',\n",
       " '_guards',\n",
       " '_has_compatible_shallow_copy_type',\n",
       " '_higher_order_ops',\n",
       " '_histogramdd_bin_edges',\n",
       " '_histogramdd_from_bin_cts',\n",
       " '_histogramdd_from_bin_tensors',\n",
       " '_import_dotted_name',\n",
       " '_index_put_impl_',\n",
       " '_indices_copy',\n",
       " '_initExtension',\n",
       " '_int_mm',\n",
       " '_is_all_true',\n",
       " '_is_any_true',\n",
       " '_is_functional_tensor',\n",
       " '_is_zerotensor',\n",
       " '_jit_internal',\n",
       " '_lazy_clone',\n",
       " '_lazy_modules',\n",
       " '_library',\n",
       " '_linalg_check_errors',\n",
       " '_linalg_det',\n",
       " '_linalg_eigh',\n",
       " '_linalg_slogdet',\n",
       " '_linalg_solve_ex',\n",
       " '_linalg_svd',\n",
       " '_linalg_utils',\n",
       " '_load_global_deps',\n",
       " '_lobpcg',\n",
       " '_log_softmax',\n",
       " '_log_softmax_backward_data',\n",
       " '_logcumsumexp',\n",
       " '_logging',\n",
       " '_lowrank',\n",
       " '_lstm_mps',\n",
       " '_lu_with_info',\n",
       " '_make_dep_token',\n",
       " '_make_dual',\n",
       " '_make_dual_copy',\n",
       " '_make_per_channel_quantized_tensor',\n",
       " '_make_per_tensor_quantized_tensor',\n",
       " '_masked_scale',\n",
       " '_masked_softmax',\n",
       " '_meta_registrations',\n",
       " '_mirror_autograd_meta_to',\n",
       " '_mixed_dtypes_linear',\n",
       " '_mkldnn',\n",
       " '_mkldnn_reshape',\n",
       " '_mkldnn_transpose',\n",
       " '_mkldnn_transpose_',\n",
       " '_mps_convolution',\n",
       " '_mps_convolution_transpose',\n",
       " '_namedtensor_internals',\n",
       " '_native_batch_norm_legit',\n",
       " '_native_batch_norm_legit_no_training',\n",
       " '_native_multi_head_attention',\n",
       " '_neg_view',\n",
       " '_neg_view_copy',\n",
       " '_nested_compute_contiguous_strides_offsets',\n",
       " '_nested_from_padded',\n",
       " '_nested_from_padded_and_nested_example',\n",
       " '_nested_get_jagged_dummy',\n",
       " '_nested_get_lengths',\n",
       " '_nested_get_offsets',\n",
       " '_nested_get_ragged_idx',\n",
       " '_nested_get_values',\n",
       " '_nested_get_values_copy',\n",
       " '_nested_tensor_from_mask',\n",
       " '_nested_tensor_from_mask_left_aligned',\n",
       " '_nested_tensor_from_tensor_list',\n",
       " '_nested_tensor_softmax_with_shape',\n",
       " '_nested_view_from_buffer',\n",
       " '_nested_view_from_buffer_copy',\n",
       " '_nested_view_from_jagged',\n",
       " '_nested_view_from_jagged_copy',\n",
       " '_nnpack_available',\n",
       " '_nnpack_spatial_convolution',\n",
       " '_ops',\n",
       " '_pack_padded_sequence',\n",
       " '_pad_packed_sequence',\n",
       " '_pin_memory',\n",
       " '_preload_cuda_deps',\n",
       " '_prelu_kernel',\n",
       " '_prims',\n",
       " '_prims_common',\n",
       " '_print',\n",
       " '_propagate_xla_data',\n",
       " '_refs',\n",
       " '_register_device_module',\n",
       " '_remove_batch_dim',\n",
       " '_reshape_alias_copy',\n",
       " '_reshape_from_tensor',\n",
       " '_resize_output_',\n",
       " '_rowwise_prune',\n",
       " '_running_with_deploy',\n",
       " '_sample_dirichlet',\n",
       " '_saturate_weight_to_fp16',\n",
       " '_scaled_dot_product_attention_math',\n",
       " '_scaled_dot_product_cudnn_attention',\n",
       " '_scaled_dot_product_efficient_attention',\n",
       " '_scaled_dot_product_flash_attention',\n",
       " '_scaled_dot_product_flash_attention_for_cpu',\n",
       " '_scaled_mm',\n",
       " '_segment_reduce',\n",
       " '_shape_as_tensor',\n",
       " '_sobol_engine_draw',\n",
       " '_sobol_engine_ff_',\n",
       " '_sobol_engine_initialize_state_',\n",
       " '_sobol_engine_scramble_',\n",
       " '_softmax',\n",
       " '_softmax_backward_data',\n",
       " '_sources',\n",
       " '_sparse_broadcast_to',\n",
       " '_sparse_broadcast_to_copy',\n",
       " '_sparse_csr_prod',\n",
       " '_sparse_csr_sum',\n",
       " '_sparse_log_softmax_backward_data',\n",
       " '_sparse_semi_structured_addmm',\n",
       " '_sparse_semi_structured_apply',\n",
       " '_sparse_semi_structured_apply_dense',\n",
       " '_sparse_semi_structured_linear',\n",
       " '_sparse_semi_structured_mm',\n",
       " '_sparse_semi_structured_tile',\n",
       " '_sparse_softmax_backward_data',\n",
       " '_sparse_sparse_matmul',\n",
       " '_sparse_sum',\n",
       " '_stack',\n",
       " '_standard_gamma',\n",
       " '_standard_gamma_grad',\n",
       " '_storage_classes',\n",
       " '_streambase',\n",
       " '_strobelight',\n",
       " '_subclasses',\n",
       " '_sym_acos',\n",
       " '_sym_asin',\n",
       " '_sym_atan',\n",
       " '_sym_cos',\n",
       " '_sym_cosh',\n",
       " '_sym_sin',\n",
       " '_sym_sinh',\n",
       " '_sym_sqrt',\n",
       " '_sym_tan',\n",
       " '_sym_tanh',\n",
       " '_sync',\n",
       " '_tensor',\n",
       " '_tensor_classes',\n",
       " '_tensor_str',\n",
       " '_test_autograd_multiple_dispatch',\n",
       " '_test_autograd_multiple_dispatch_view',\n",
       " '_test_autograd_multiple_dispatch_view_copy',\n",
       " '_test_check_tensor',\n",
       " '_test_functorch_fallback',\n",
       " '_test_parallel_materialize',\n",
       " '_test_serialization_subcmul',\n",
       " '_to_cpu',\n",
       " '_to_functional_tensor',\n",
       " '_to_sparse_semi_structured',\n",
       " '_transform_bias_rescale_qkv',\n",
       " '_transformer_encoder_layer_fwd',\n",
       " '_trilinear',\n",
       " '_triton_multi_head_attention',\n",
       " '_triton_scaled_dot_attention',\n",
       " '_unique',\n",
       " '_unique2',\n",
       " '_unpack_dual',\n",
       " '_unsafe_index',\n",
       " '_unsafe_index_put',\n",
       " '_use_cudnn_ctc_loss',\n",
       " '_use_cudnn_rnn_flatten_weight',\n",
       " '_utils',\n",
       " '_utils_internal',\n",
       " '_validate_compressed_sparse_indices',\n",
       " '_validate_sparse_bsc_tensor_args',\n",
       " '_validate_sparse_bsr_tensor_args',\n",
       " '_validate_sparse_compressed_tensor_args',\n",
       " '_validate_sparse_coo_tensor_args',\n",
       " '_validate_sparse_csc_tensor_args',\n",
       " '_validate_sparse_csr_tensor_args',\n",
       " '_values_copy',\n",
       " '_vendor',\n",
       " '_vmap_internals',\n",
       " '_warn_typed_storage_removal',\n",
       " '_weight_int4pack_mm',\n",
       " '_weight_int8pack_mm',\n",
       " '_weight_norm',\n",
       " '_weight_norm_interface',\n",
       " '_weights_only_unpickler',\n",
       " 'abs',\n",
       " 'abs_',\n",
       " 'absolute',\n",
       " 'acos',\n",
       " 'acos_',\n",
       " 'acosh',\n",
       " 'acosh_',\n",
       " 'adaptive_avg_pool1d',\n",
       " 'adaptive_max_pool1d',\n",
       " 'add',\n",
       " 'addbmm',\n",
       " 'addcdiv',\n",
       " 'addcmul',\n",
       " 'addmm',\n",
       " 'addmv',\n",
       " 'addmv_',\n",
       " 'addr',\n",
       " 'adjoint',\n",
       " 'affine_grid_generator',\n",
       " 'alias_copy',\n",
       " 'align_tensors',\n",
       " 'all',\n",
       " 'allclose',\n",
       " 'alpha_dropout',\n",
       " 'alpha_dropout_',\n",
       " 'amax',\n",
       " 'amin',\n",
       " 'aminmax',\n",
       " 'amp',\n",
       " 'angle',\n",
       " 'any',\n",
       " 'ao',\n",
       " 'arange',\n",
       " 'arccos',\n",
       " 'arccos_',\n",
       " 'arccosh',\n",
       " 'arccosh_',\n",
       " 'arcsin',\n",
       " 'arcsin_',\n",
       " 'arcsinh',\n",
       " 'arcsinh_',\n",
       " 'arctan',\n",
       " 'arctan2',\n",
       " 'arctan_',\n",
       " 'arctanh',\n",
       " 'arctanh_',\n",
       " 'are_deterministic_algorithms_enabled',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'argwhere',\n",
       " 'as_strided',\n",
       " 'as_strided_',\n",
       " 'as_strided_copy',\n",
       " 'as_strided_scatter',\n",
       " 'as_tensor',\n",
       " 'asarray',\n",
       " 'asin',\n",
       " 'asin_',\n",
       " 'asinh',\n",
       " 'asinh_',\n",
       " 'atan',\n",
       " 'atan2',\n",
       " 'atan_',\n",
       " 'atanh',\n",
       " 'atanh_',\n",
       " 'atleast_1d',\n",
       " 'atleast_2d',\n",
       " 'atleast_3d',\n",
       " 'autocast',\n",
       " 'autocast_decrement_nesting',\n",
       " 'autocast_increment_nesting',\n",
       " 'autograd',\n",
       " 'avg_pool1d',\n",
       " 'backends',\n",
       " 'baddbmm',\n",
       " 'bartlett_window',\n",
       " 'base_py_dll_path',\n",
       " 'batch_norm',\n",
       " 'batch_norm_backward_elemt',\n",
       " 'batch_norm_backward_reduce',\n",
       " 'batch_norm_elemt',\n",
       " 'batch_norm_gather_stats',\n",
       " 'batch_norm_gather_stats_with_counts',\n",
       " 'batch_norm_stats',\n",
       " 'batch_norm_update_stats',\n",
       " 'bernoulli',\n",
       " 'bfloat16',\n",
       " 'bilinear',\n",
       " 'binary_cross_entropy_with_logits',\n",
       " 'bincount',\n",
       " 'binomial',\n",
       " 'bit',\n",
       " 'bits16',\n",
       " 'bits1x8',\n",
       " 'bits2x4',\n",
       " 'bits4x2',\n",
       " 'bits8',\n",
       " 'bitwise_and',\n",
       " 'bitwise_left_shift',\n",
       " 'bitwise_not',\n",
       " 'bitwise_or',\n",
       " 'bitwise_right_shift',\n",
       " 'bitwise_xor',\n",
       " 'blackman_window',\n",
       " 'block_diag',\n",
       " 'bmm',\n",
       " 'bool',\n",
       " 'broadcast_shapes',\n",
       " 'broadcast_tensors',\n",
       " 'broadcast_to',\n",
       " 'bucketize',\n",
       " 'builtins',\n",
       " 'can_cast',\n",
       " 'cartesian_prod',\n",
       " 'cat',\n",
       " 'ccol_indices_copy',\n",
       " 'cdist',\n",
       " 'cdouble',\n",
       " 'ceil',\n",
       " 'ceil_',\n",
       " 'celu',\n",
       " 'celu_',\n",
       " 'cfloat',\n",
       " 'chain_matmul',\n",
       " 'chalf',\n",
       " 'channel_shuffle',\n",
       " 'channels_last',\n",
       " 'channels_last_3d',\n",
       " 'cholesky',\n",
       " 'cholesky_inverse',\n",
       " 'cholesky_solve',\n",
       " 'choose_qparams_optimized',\n",
       " 'chunk',\n",
       " 'clamp',\n",
       " 'clamp_',\n",
       " 'clamp_max',\n",
       " 'clamp_max_',\n",
       " 'clamp_min',\n",
       " 'clamp_min_',\n",
       " 'classes',\n",
       " 'classproperty',\n",
       " 'clear_autocast_cache',\n",
       " 'clip',\n",
       " 'clip_',\n",
       " 'clone',\n",
       " 'col_indices_copy',\n",
       " 'column_stack',\n",
       " 'combinations',\n",
       " 'compile',\n",
       " 'compiled_with_cxx11_abi',\n",
       " 'compiler',\n",
       " 'complex',\n",
       " 'complex128',\n",
       " 'complex32',\n",
       " 'complex64',\n",
       " 'concat',\n",
       " 'concatenate',\n",
       " 'cond',\n",
       " 'conj',\n",
       " 'conj_physical',\n",
       " 'conj_physical_',\n",
       " 'constant_pad_nd',\n",
       " 'contiguous_format',\n",
       " 'conv1d',\n",
       " 'conv2d',\n",
       " 'conv3d',\n",
       " 'conv_tbc',\n",
       " 'conv_transpose1d',\n",
       " 'conv_transpose2d',\n",
       " 'conv_transpose3d',\n",
       " 'convolution',\n",
       " 'copysign',\n",
       " 'corrcoef',\n",
       " 'cos',\n",
       " 'cos_',\n",
       " 'cosh',\n",
       " 'cosh_',\n",
       " 'cosine_embedding_loss',\n",
       " 'cosine_similarity',\n",
       " 'count_nonzero',\n",
       " 'cov',\n",
       " 'cpp',\n",
       " 'cpu',\n",
       " 'cross',\n",
       " 'crow_indices_copy',\n",
       " 'ctc_loss',\n",
       " 'ctypes',\n",
       " 'cuda',\n",
       " 'cuda_path',\n",
       " 'cuda_version',\n",
       " 'cudnn_affine_grid_generator',\n",
       " 'cudnn_batch_norm',\n",
       " 'cudnn_convolution',\n",
       " 'cudnn_convolution_add_relu',\n",
       " 'cudnn_convolution_relu',\n",
       " 'cudnn_convolution_transpose',\n",
       " 'cudnn_grid_sampler',\n",
       " 'cudnn_is_acceptable',\n",
       " 'cummax',\n",
       " 'cummin',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'cumulative_trapezoid',\n",
       " 'default_generator',\n",
       " 'deg2rad',\n",
       " 'deg2rad_',\n",
       " 'dequantize',\n",
       " 'det',\n",
       " 'detach',\n",
       " 'detach_',\n",
       " 'detach_copy',\n",
       " 'device',\n",
       " 'diag',\n",
       " 'diag_embed',\n",
       " 'diagflat',\n",
       " 'diagonal',\n",
       " 'diagonal_copy',\n",
       " 'diagonal_scatter',\n",
       " 'diff',\n",
       " 'digamma',\n",
       " 'dist',\n",
       " 'distributed',\n",
       " 'distributions',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'dll',\n",
       " 'dll_path',\n",
       " 'dll_paths',\n",
       " 'dlls',\n",
       " 'dot',\n",
       " 'double',\n",
       " 'dropout',\n",
       " 'dropout_',\n",
       " 'dsmm',\n",
       " 'dsplit',\n",
       " 'dstack',\n",
       " 'dtype',\n",
       " 'e',\n",
       " 'eig',\n",
       " 'einsum',\n",
       " 'embedding',\n",
       " 'embedding_bag',\n",
       " 'embedding_renorm_',\n",
       " 'empty',\n",
       " 'empty_like',\n",
       " 'empty_permuted',\n",
       " 'empty_quantized',\n",
       " 'empty_strided',\n",
       " 'enable_grad',\n",
       " 'eq',\n",
       " 'equal',\n",
       " 'erf',\n",
       " 'erf_',\n",
       " 'erfc',\n",
       " 'erfc_',\n",
       " 'erfinv',\n",
       " 'exp',\n",
       " 'exp2',\n",
       " 'exp2_',\n",
       " 'exp_',\n",
       " 'expand_copy',\n",
       " 'expm1',\n",
       " 'expm1_',\n",
       " 'export',\n",
       " 'eye',\n",
       " 'fake_quantize_per_channel_affine',\n",
       " 'fake_quantize_per_tensor_affine',\n",
       " 'fbgemm_linear_fp16_weight',\n",
       " 'fbgemm_linear_fp16_weight_fp32_activation',\n",
       " 'fbgemm_linear_int8_weight',\n",
       " 'fbgemm_linear_int8_weight_fp32_activation',\n",
       " 'fbgemm_linear_quantize_weight',\n",
       " 'fbgemm_pack_gemm_matrix_fp16',\n",
       " 'fbgemm_pack_quantized_matrix',\n",
       " 'feature_alpha_dropout',\n",
       " 'feature_alpha_dropout_',\n",
       " 'feature_dropout',\n",
       " 'feature_dropout_',\n",
       " 'fft',\n",
       " 'fill',\n",
       " 'fill_',\n",
       " 'finfo',\n",
       " 'fix',\n",
       " 'fix_',\n",
       " 'flatten',\n",
       " 'flip',\n",
       " 'fliplr',\n",
       " 'flipud',\n",
       " 'float',\n",
       " 'float16',\n",
       " 'float32',\n",
       " 'float64',\n",
       " 'float8_e4m3fn',\n",
       " 'float8_e4m3fnuz',\n",
       " 'float8_e5m2',\n",
       " 'float8_e5m2fnuz',\n",
       " 'float_power',\n",
       " 'floor',\n",
       " 'floor_',\n",
       " 'floor_divide',\n",
       " 'fmax',\n",
       " 'fmin',\n",
       " 'fmod',\n",
       " 'fork',\n",
       " 'frac',\n",
       " 'frac_',\n",
       " 'frexp',\n",
       " 'frobenius_norm',\n",
       " 'from_dlpack',\n",
       " 'from_file',\n",
       " 'from_numpy',\n",
       " 'frombuffer',\n",
       " 'full',\n",
       " 'full_like',\n",
       " 'func',\n",
       " 'functional',\n",
       " 'fused_moving_avg_obs_fake_quant',\n",
       " 'futures',\n",
       " 'fx',\n",
       " 'gather',\n",
       " 'gcd',\n",
       " 'gcd_',\n",
       " 'ge',\n",
       " 'geqrf',\n",
       " 'ger',\n",
       " 'get_autocast_cpu_dtype',\n",
       " 'get_autocast_dtype',\n",
       " 'get_autocast_gpu_dtype',\n",
       " 'get_autocast_ipu_dtype',\n",
       " 'get_autocast_xla_dtype',\n",
       " 'get_default_device',\n",
       " 'get_default_dtype',\n",
       " 'get_deterministic_debug_mode',\n",
       " 'get_device',\n",
       " 'get_device_module',\n",
       " 'get_file_path',\n",
       " 'get_float32_matmul_precision',\n",
       " 'get_num_interop_threads',\n",
       " 'get_num_threads',\n",
       " 'get_rng_state',\n",
       " 'glob',\n",
       " 'gradient',\n",
       " 'greater',\n",
       " 'greater_equal',\n",
       " 'grid_sampler',\n",
       " 'grid_sampler_2d',\n",
       " 'grid_sampler_3d',\n",
       " 'group_norm',\n",
       " 'gru',\n",
       " 'gru_cell',\n",
       " 'gt',\n",
       " 'half',\n",
       " 'hamming_window',\n",
       " 'hann_window',\n",
       " 'hardshrink',\n",
       " 'has_lapack',\n",
       " 'has_mkl',\n",
       " 'has_openmp',\n",
       " 'has_spectral',\n",
       " 'heaviside',\n",
       " 'hinge_embedding_loss',\n",
       " 'histc',\n",
       " 'histogram',\n",
       " 'histogramdd',\n",
       " 'hsmm',\n",
       " 'hsplit',\n",
       " 'hspmm',\n",
       " 'hstack',\n",
       " 'hub',\n",
       " 'hypot',\n",
       " 'i0',\n",
       " 'i0_',\n",
       " 'igamma',\n",
       " 'igammac',\n",
       " 'iinfo',\n",
       " 'imag',\n",
       " 'import_ir_module',\n",
       " 'import_ir_module_from_buffer',\n",
       " 'importlib',\n",
       " 'index_add',\n",
       " 'index_copy',\n",
       " 'index_fill',\n",
       " 'index_put',\n",
       " 'index_put_',\n",
       " 'index_reduce',\n",
       " 'index_select',\n",
       " 'indices_copy',\n",
       " 'inf',\n",
       " 'inference_mode',\n",
       " 'init_num_threads',\n",
       " 'initial_seed',\n",
       " 'inner',\n",
       " 'inspect',\n",
       " 'instance_norm',\n",
       " 'int',\n",
       " 'int16',\n",
       " 'int32',\n",
       " 'int64',\n",
       " 'int8',\n",
       " 'int_repr',\n",
       " 'inverse',\n",
       " 'is_anomaly_check_nan_enabled',\n",
       " 'is_anomaly_enabled',\n",
       " 'is_autocast_cache_enabled',\n",
       " 'is_autocast_cpu_enabled',\n",
       " 'is_autocast_enabled',\n",
       " 'is_autocast_ipu_enabled',\n",
       " 'is_autocast_xla_enabled',\n",
       " 'is_complex',\n",
       " 'is_conj',\n",
       " 'is_deterministic_algorithms_warn_only_enabled',\n",
       " 'is_distributed',\n",
       " 'is_floating_point',\n",
       " 'is_grad_enabled',\n",
       " 'is_inference',\n",
       " 'is_inference_mode_enabled',\n",
       " 'is_loaded',\n",
       " 'is_neg',\n",
       " 'is_nonzero',\n",
       " 'is_same_size',\n",
       " 'is_signed',\n",
       " 'is_storage',\n",
       " 'is_tensor',\n",
       " 'is_vulkan_available',\n",
       " 'is_warn_always_enabled',\n",
       " 'isclose',\n",
       " 'isfinite',\n",
       " 'isin',\n",
       " 'isinf',\n",
       " 'isnan',\n",
       " 'isneginf',\n",
       " 'isposinf',\n",
       " 'isreal',\n",
       " 'istft',\n",
       " 'jagged',\n",
       " 'jit',\n",
       " 'kaiser_window',\n",
       " 'kernel32',\n",
       " 'kl_div',\n",
       " 'kron',\n",
       " 'kthvalue',\n",
       " 'last_error',\n",
       " 'layer_norm',\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
       "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
       "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
       "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
       "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
       "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
       "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
       "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
       "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
       "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
       "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
       "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
       "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
       "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
       "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
       "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
       "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
       "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
       "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
       "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
       "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
       "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
       "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
       "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
       "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
       "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
       "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
       "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
       "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
       "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
       "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
       "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
       "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
       "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
       "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
       "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
       "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
       "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
       "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
       "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
       "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
       "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
       "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
       "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
       "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
       "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
       "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
       "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
       "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
       "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
       "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
       "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
       "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
       "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
       "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
       "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1000]   # the  characters we looked at earier will to the GPT look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(data.shape, data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now split up the data into train and validation sets\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target: 47\n",
      "when input is tensor([18, 47]) the target: 56\n",
      "when input is tensor([18, 47, 56]) the target: 57\n",
      "when input is tensor([18, 47, 56, 57]) the target: 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([], dtype=torch.int64) the target: 18\n",
      "when input is tensor([18]) the target: 47\n",
      "when input is tensor([18, 47]) the target: 56\n",
      "when input is tensor([18, 47, 56]) the target: 57\n",
      "when input is tensor([18, 47, 56, 57]) the target: 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n"
     ]
    }
   ],
   "source": [
    "for t in range(block_size):\n",
    "    context = x[:t]\n",
    "    target = x[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 7])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(10, (2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = torch.randint(len(train_data) - block_size, (batch_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([934904, 560986, 971401, 579495])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([52, 58,  1, 58, 46, 39, 58,  1]),\n",
       " tensor([25, 17, 27, 10,  0, 21,  1, 54]),\n",
       " tensor([57, 43, 60, 43, 52,  1, 63, 43]),\n",
       " tensor([60, 43, 42,  8,  0, 25, 63,  1])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[data[i:i+block_size] for i in ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.stack([data[i:i+block_size] for i in ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[52, 58,  1, 58, 46, 39, 58,  1],\n",
       "        [25, 17, 27, 10,  0, 21,  1, 54],\n",
       "        [57, 43, 60, 43, 52,  1, 63, 43],\n",
       "        [60, 43, 42,  8,  0, 25, 63,  1]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([58,  1, 58, 46, 39, 58,  1, 46]),\n",
       " tensor([17, 27, 10,  0, 21,  1, 54, 39]),\n",
       " tensor([43, 60, 43, 52,  1, 63, 43, 39]),\n",
       " tensor([43, 42,  8,  0, 25, 63,  1, 45])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[data[i+1:i+block_size+1] for i in ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.stack([data[i+1:i+block_size+1] for i in ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[58,  1, 58, 46, 39, 58,  1, 46],\n",
       "        [17, 27, 10,  0, 21,  1, 54, 39],\n",
       "        [43, 60, 43, 52,  1, 63, 43, 39],\n",
       "        [43, 42,  8,  0, 25, 63,  1, 45]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[56, 42,  5, 57,  1, 57, 39, 49],\n",
       "        [43, 57, 58, 63,  6,  1, 58, 46],\n",
       "        [43,  1, 51, 39, 63,  1, 40, 43],\n",
       "        [58, 46, 43,  1, 43, 39, 56, 57]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[42,  5, 57,  1, 57, 39, 49, 43],\n",
       "        [57, 58, 63,  6,  1, 58, 46, 47],\n",
       "        [ 1, 51, 39, 63,  1, 40, 43,  1],\n",
       "        [46, 43,  1, 43, 39, 56, 57, 10]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[56, 42,  5, 57,  1, 57, 39, 49],\n",
      "        [43, 57, 58, 63,  6,  1, 58, 46],\n",
      "        [43,  1, 51, 39, 63,  1, 40, 43],\n",
      "        [58, 46, 43,  1, 43, 39, 56, 57]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[42,  5, 57,  1, 57, 39, 49, 43],\n",
      "        [57, 58, 63,  6,  1, 58, 46, 47],\n",
      "        [ 1, 51, 39, 63,  1, 40, 43,  1],\n",
      "        [46, 43,  1, 43, 39, 56, 57, 10]])\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is [56] the target: 42\n",
      "when input is [56, 42] the target: 5\n",
      "when input is [56, 42, 5] the target: 57\n",
      "when input is [56, 42, 5, 57] the target: 1\n",
      "when input is [56, 42, 5, 57, 1] the target: 57\n",
      "when input is [56, 42, 5, 57, 1, 57] the target: 39\n",
      "when input is [56, 42, 5, 57, 1, 57, 39] the target: 49\n",
      "when input is [56, 42, 5, 57, 1, 57, 39, 49] the target: 43\n",
      "when input is [43] the target: 57\n",
      "when input is [43, 57] the target: 58\n",
      "when input is [43, 57, 58] the target: 63\n",
      "when input is [43, 57, 58, 63] the target: 6\n",
      "when input is [43, 57, 58, 63, 6] the target: 1\n",
      "when input is [43, 57, 58, 63, 6, 1] the target: 58\n",
      "when input is [43, 57, 58, 63, 6, 1, 58] the target: 46\n",
      "when input is [43, 57, 58, 63, 6, 1, 58, 46] the target: 47\n",
      "when input is [43] the target: 1\n",
      "when input is [43, 1] the target: 51\n",
      "when input is [43, 1, 51] the target: 39\n",
      "when input is [43, 1, 51, 39] the target: 63\n",
      "when input is [43, 1, 51, 39, 63] the target: 1\n",
      "when input is [43, 1, 51, 39, 63, 1] the target: 40\n",
      "when input is [43, 1, 51, 39, 63, 1, 40] the target: 43\n",
      "when input is [43, 1, 51, 39, 63, 1, 40, 43] the target: 1\n",
      "when input is [58] the target: 46\n",
      "when input is [58, 46] the target: 43\n",
      "when input is [58, 46, 43] the target: 1\n",
      "when input is [58, 46, 43, 1] the target: 43\n",
      "when input is [58, 46, 43, 1, 43] the target: 39\n",
      "when input is [58, 46, 43, 1, 43, 39] the target: 56\n",
      "when input is [58, 46, 43, 1, 43, 39, 56] the target: 57\n",
      "when input is [58, 46, 43, 1, 43, 39, 56, 57] the target: 10\n"
     ]
    }
   ],
   "source": [
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[56, 42,  5, 57,  1, 57, 39, 49],\n",
      "        [43, 57, 58, 63,  6,  1, 58, 46],\n",
      "        [43,  1, 51, 39, 63,  1, 40, 43],\n",
      "        [58, 46, 43,  1, 43, 39, 56, 57]])\n"
     ]
    }
   ],
   "source": [
    "print(xb) # our input to the transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x29496d6a690>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BigramLanguageModel class is a PyTorch neural network module that implements a simple bigram language model. A bigram language model predicts the next token in a sequence based on the current token."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model consists of a single embedding table (token_embedding_table) that maps each token in the vocabulary to a vector of size vocab_size. This embedding table serves as a lookup table for the next token's logits.\n",
    "# __init__ Method\n",
    "# The __init__ method initializes the model by creating the token_embedding_table with the specified vocab_size.\n",
    "# forward Method\n",
    "# The forward method defines the forward pass through the network. It takes two inputs:\n",
    "# idx: A tensor of shape (B, T) containing the indices of the input tokens.\n",
    "# targets: An optional tensor of shape (B, T) containing the indices of the target tokens.\n",
    "# The method returns two outputs:\n",
    "# logits: A tensor of shape (B, T, C) containing the logits for the next token.\n",
    "# loss: The cross-entropy loss between the predicted logits and the target tokens (if targets is provided).\n",
    "# generate Method\n",
    "# he generate method generates new tokens based on the input context. It takes two inputs:\n",
    "# idx: A tensor of shape (B, T) containing the indices of the input context.\n",
    "# max_new_tokens: The maximum number of new tokens to generate.\n",
    "# The method returns the generated sequence of tokens, which includes the original input context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None): # idx = input tokens and targets = target tokens\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code defines a token embedding table using PyTorch's nn.Embedding module.\n",
    "# What is an Embedding Table?\n",
    "# An embedding table is a learnable matrix that maps discrete tokens (e.g., words, characters) to dense vectors. These vectors, called embeddings, capture the semantic meaning of the tokens.\n",
    "# Parameters:\n",
    "# vocab_size: The number of unique tokens in the vocabulary.\n",
    "# vocab_size: The dimensionality of the embedding vectors.\n",
    "# How it Works:\n",
    "# The nn.Embedding module creates a matrix of shape (vocab_size, vocab_size).\n",
    "# Each row in the matrix represents a token in the vocabulary.\n",
    "# Each column in the matrix represents a dimension in the embedding space.\n",
    "# During training, the model learns to update the embedding table to capture meaningful relationships between tokens.\n",
    "# Why Use an Embedding Table?\n",
    "# Using an embedding table provides several benefits:\n",
    "# Efficient representation: Embedding tables can represent large vocabularies using a relatively small number of parameters.\n",
    "# Captures semantic meaning: Embeddings can capture nuanced relationships between tokens, such as synonyms, antonyms, and analogies.\n",
    "# Improves model performance: Using pre-trained embeddings or learning embeddings during training can significantly improve the performance of NLP models.\n",
    "# In the context of the BigramLanguageModel class, the token embedding table is used to map input tokens to their corresponding embedding vectors, which are then used to predict the next token in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Here's a succinct yet thorough explanation of the code:\n",
    "# Code Breakdown:\n",
    "# Python\n",
    "# logits = logits.view(B*T, C)\n",
    "# targets = targets.view(B*T)\n",
    "# Explanation:\n",
    "# This code reshapes the logits and targets tensors using the view() method.\n",
    "# logits:\n",
    "# logits.view(B*T, C): Reshapes the logits tensor from its original shape (B, T, C) to a new shape (B*T, C).\n",
    "# B: Batch size (number of input sequences)\n",
    "# T: Sequence length (number of time steps)\n",
    "# C: Number of classes or output units\n",
    "# targets:\n",
    "# targets.view(B*T): Reshapes the targets tensor from its original shape (B, T) to a new shape (B*T,).\n",
    "# B: Batch size (number of input sequences)\n",
    "# T: Sequence length (number of time steps)\n",
    "# Why Reshape?\n",
    "# Reshaping the tensors is necessary for the following reasons:\n",
    "# Flattening the sequence dimension: By reshaping (B, T, C) to (B*T, C), we flatten the sequence dimension (B, T) into a single dimension (B*T). This allows us to treat each time step as a separate sample.\n",
    "# Matching the loss function's expectations: The cross_entropy loss function expects the input tensor to have shape (N, C), where N is the number of samples and C is the number of classes. By reshaping the tensors, we ensure that they match the expected shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the number of new tokens to generate: The method loops max_new_tokens times to generate new tokens one by one.\n",
    "# Get the predictions: In each iteration, the method calls the model's forward method with the current input context idx to get the predictions (logits and loss).\n",
    "# Focus on the last time step: The method selects only the last time step's logits by indexing logits[:, -1, :]. This gives a tensor of shape (B, C), where B is the batch size and C is the number of classes.\n",
    "# Apply softmax to get probabilities: The method applies the softmax activation function to the logits using F.softmax(logits, dim=-1). This gives a tensor of shape (B, C) containing probabilities.\n",
    "# Sample from the distribution: The method samples from the probability distribution using torch.multinomial(probs, num_samples=1). This gives a tensor of shape (B, 1) containing the indices of the sampled tokens.\n",
    "# Append the sampled index to the running sequence: The method appends the sampled index to the running sequence idx using torch.cat((idx, idx_next), dim=1).\n",
    "# Return the generated sequence: After generating all the new tokens, the method returns the final generated sequence idx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size # length of the uniqe characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = BigramLanguageModel(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BigramLanguageModel(\n",
       "  (token_embedding_table): Embedding(65, 65)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(65, 65)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.token_embedding_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[56, 42,  5, 57,  1, 57, 39, 49],\n",
       "        [43, 57, 58, 63,  6,  1, 58, 46],\n",
       "        [43,  1, 51, 39, 63,  1, 40, 43],\n",
       "        [58, 46, 43,  1, 43, 39, 56, 57]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[42,  5, 57,  1, 57, 39, 49, 43],\n",
       "        [57, 58, 63,  6,  1, 58, 46, 47],\n",
       "        [ 1, 51, 39, 63,  1, 40, 43,  1],\n",
       "        [46, 43,  1, 43, 39, 56, 57, 10]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logits:  Unnormalized scores that can take on any real value. Logits represent the \"raw\" output of a model. before applying the activation function\n",
    "\n",
    "Probabilities:  Normalized values between 0 and 1 that represent the likelihood of a particular outcome. Probabilities are often obtained by applying an activation function, such as softmax or sigmoid, to the logits. after applying activation function, like softmax , sigmoid etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, loss = m(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code calls the forward method of a PyTorch neural network model m, passing in two inputs:\n",
    "# xb: A batch of input data (e.g., images, text, etc.)\n",
    "# yb: A batch of corresponding target labels or outputs\n",
    "# The forward method returns two values:\n",
    "# logits: The model's predictions or output scores (before applying an activation function)\n",
    "# loss: The calculated loss or error between the model's predictions and the target labels\n",
    "# What the Code Does:\n",
    "# When you call this code:\n",
    "# The model m processes the input batch xb through its layers.\n",
    "# The model generates output scores or logits.\n",
    "# The model calculates the loss between its predictions and the target labels yb.\n",
    "# The logits and loss values are returned and assigned to the variables logits and loss, respectively.\n",
    "# The logits and loss values can then be used for various purposes, such as:\n",
    "# Evaluating the model's performance\n",
    "# Training the model using backpropagation\n",
    "# Generating predictions or outputs for new input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6722,  0.2322, -0.1632,  ...,  0.1390,  0.7560,  0.4296],\n",
       "        [ 1.0726,  0.7295, -0.6665,  ...,  0.3115, -1.7675,  0.6818],\n",
       "        [-0.1338,  0.3899, -0.2884,  ..., -0.5512,  1.0477,  1.6187],\n",
       "        ...,\n",
       "        [ 1.1513,  1.0539,  3.4105,  ..., -0.5686,  0.9079, -0.1701],\n",
       "        [-0.6722,  0.2322, -0.1632,  ...,  0.1390,  0.7560,  0.4296],\n",
       "        [-0.5201,  0.2831,  1.0847,  ..., -0.0198,  0.7959,  1.6014]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 65])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6722,  0.2322, -0.1632,  0.5926,  1.7734,  1.2618,  0.6474, -0.3519,\n",
       "         1.0237, -0.1184,  0.1446,  0.0477, -0.4317,  0.0058, -0.3478, -0.2188,\n",
       "         1.2574, -0.7758,  0.9081, -1.1492, -1.6415,  1.3099,  1.2829, -0.9754,\n",
       "         0.5888, -0.3234, -0.9876, -0.1603, -0.2273,  0.6294, -0.4703, -0.1420,\n",
       "        -1.0257,  0.3648,  0.8021,  0.5142, -1.0679, -0.6295, -0.1167, -0.0337,\n",
       "         0.2609, -0.2877,  1.7954,  0.6843, -0.8268,  1.8204,  0.3783,  0.5864,\n",
       "        -0.2330, -0.3098,  0.7679, -0.0269,  0.6213, -1.3444, -1.3337,  0.2562,\n",
       "        -1.1706, -0.5799, -1.1549,  0.4594,  0.1099, -0.4593,  0.1390,  0.7560,\n",
       "         0.4296], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0726,  0.7295, -0.6665, -0.4071,  1.0580,  0.7095,  1.8728, -0.8542,\n",
       "         0.4089, -0.6644, -0.7699, -0.5311,  1.3702, -0.6511, -1.3560, -1.5675,\n",
       "        -0.5239,  0.6937, -0.1874, -0.4551, -0.0516, -0.4424,  0.1604, -1.1646,\n",
       "         0.6482, -1.6310, -0.5834, -1.7104,  0.6697, -1.2521, -0.3970,  0.3250,\n",
       "        -1.0091, -0.0558, -0.4422, -0.1064,  0.4973,  0.6844,  1.6967,  1.2412,\n",
       "         1.2617,  1.3472,  1.3725, -0.3011,  0.6546,  0.1393,  0.9892, -1.0955,\n",
       "        -0.7337, -0.5563,  1.1861,  1.0686, -0.8841, -1.4150, -0.2771, -0.3126,\n",
       "        -0.9772, -0.5400, -0.2355,  0.8232, -0.5872, -0.7521,  0.3115, -1.7675,\n",
       "         0.6818], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.5039, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 31, 56, 12, 55, 28,  7, 29, 35, 49, 58, 36, 53, 24,  4, 48, 24, 16,\n",
       "         22, 45, 27, 24, 34, 64,  5, 30, 21, 53, 16, 55, 20, 42, 46, 57, 34,  4,\n",
       "         60, 24, 24, 62, 39, 58, 48, 57, 41, 25, 54, 61, 24, 17, 30, 31, 28, 63,\n",
       "         39, 53,  8, 55, 44, 64, 57,  3, 37, 57,  3, 64, 18,  7, 61,  6, 11, 43,\n",
       "         17, 49, 64, 62, 48, 45, 15, 23, 18, 15, 46, 57,  2, 47, 35, 35,  8, 27,\n",
       "         40, 64, 16, 52, 62, 13,  1, 25, 57,  3,  9]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "# This code calls the generate method of an object m, which is likely an instance of a language model class.\n",
    "# idx Argument:\n",
    "# torch.zeros((1, 1), dtype=torch.long): Creates a tensor filled with zeros, with shape (1, 1) and data type torch.long (which represents long integers).\n",
    "# This tensor represents the initial input to the language model, which is a single token with index 0.\n",
    "# max_new_tokens Argument:\n",
    "# max_new_tokens=100: Specifies the maximum number of new tokens to generate.\n",
    "# The language model will generate new tokens one by one, conditioning on the previous tokens, until it reaches the maximum number of tokens specified.\n",
    "# What the Code Does:\n",
    "# When you call this code, the language model will:\n",
    "# Start with the initial input token (index 0).\n",
    "# Generate a new token based on the initial input token.\n",
    "# Append the new token to the input sequence.\n",
    "# Repeat steps 2-3 until it reaches the maximum number of tokens specified (100 in this case).\n",
    "# Return the generated sequence of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([ 0, 31, 56, 12, 55, 28,  7, 29, 35, 49, 58, 36, 53, 24,  4, 48, 24, 16,\n",
    "         22, 45, 27, 24, 34, 64,  5, 30, 21, 53, 16, 55, 20, 42, 46, 57, 34,  4,\n",
    "         60, 24, 24, 62, 39, 58, 48, 57, 41, 25, 54, 61, 24, 17, 30, 31, 28, 63,\n",
    "         39, 53,  8, 55, 44, 64, 57,  3, 37, 57,  3, 64, 18,  7, 61,  6, 11, 43,\n",
    "         17, 49, 64, 62, 48, 45, 15, 23, 18, 15, 46, 57,  2, 47, 35, 35,  8, 27,\n",
    "         40, 64, 16, 52, 62, 13,  1, 25, 57,  3,  9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pdcbf?pGXepydZJSrF$Jrqt!:wwWSzPNxbjPiD&Q!a;yNt$Kr$o-gC$WSjJqfBKBySKtSKpwNNfyl&w:q-jluBatD$Lj;?yzyUca\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample a batch of data\n",
    "xb, yb = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[42,  1, 51, 63,  1, 15, 56, 43],\n",
       "        [47, 57,  1, 46, 59, 51, 40, 50],\n",
       "        [39, 60, 43,  1, 58, 53,  1, 50],\n",
       "        [43, 52,  6,  1, 53, 59, 56,  1]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 51, 63,  1, 15, 56, 43, 39],\n",
       "        [57,  1, 46, 59, 51, 40, 50, 43],\n",
       "        [60, 43,  1, 58, 53,  1, 50, 53],\n",
       "        [52,  6,  1, 53, 59, 56,  1, 57]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the loss\n",
    "logits, loss = m(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0726,  0.7295, -0.6665,  ...,  0.3115, -1.7675,  0.6818],\n",
       "        [ 0.5978, -0.0514, -0.0646,  ..., -1.4649, -2.0555,  1.8275],\n",
       "        [-1.4177,  0.8682, -0.9121,  ..., -0.6264,  1.2195,  0.2068],\n",
       "        ...,\n",
       "        [-0.4002,  0.3302,  1.5454,  ...,  1.3688,  0.4620,  0.2040],\n",
       "        [-0.6722,  0.2322, -0.1632,  ...,  0.1390,  0.7560,  0.4296],\n",
       "        [ 0.5978, -0.0514, -0.0646,  ..., -1.4649, -2.0555,  1.8275]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.7769, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad(set_to_none=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51960563659668\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(100): # increase number of steps for good results...\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SPCAuCX:bOlgiRQWN:Mphaw\n",
      "tRLKuYXEaAXxrcq-gCUzeh3w!AcyaylgYWjmJM?Uzw:inaY,:C&OECW:vmGGJAn3onAuMgia!ms$Vb q-gCOcPcUhOnxJGUGSPJWT:.?ujmJFoiNL&A'DxY,prZ?qdT;hoo'dHooXXlxf'WkHK&u3Q?rqUi.kz;?Yx?C&u3Qbfzxlyh'Vl:zyxjKXgC?\n",
      "lv'QKFiBeviNxO'm!Upm$srm&TqViqiBD3HBP!juEOpmZJyF$Fwfy!PlvWPFC\n",
      "&WDdP!Ko,px\n",
      "x\n",
      "tREOE;AJ.BeXkylOVD3KHp$e?nD,.SFbWWI'ubcL!q-tU;aXmJ&uGXHxJXI&Z!gHRpajj;l.\n",
      "pTErIBjx;JKIgoCnLGXrJSP!AU-AcbczR?aytqQmBxZb:txqfSBj$I&\n",
      "gXxy,j,SYgOmgXAaVzLXxlVSP!uSq 3!UM&vcL&yN!zXiA.da-mZ3Izkm!a;Ilkzdd -gwCjN.ivvhM;TB\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mathematical trick in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x29496d6a690>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tril(torch.ones(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(a, 1, keepdim=True) # over axis 1 or column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a / torch.sum(a, 1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randint(0,10,(3,2)) # lower bound, upper bound, shape(row, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 4],\n",
       "        [1, 2],\n",
       "        [5, 5]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=b.float() # lower bound, upper bound, shape(row, column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a # 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 4.],\n",
       "        [1., 2.],\n",
       "        [5., 5.]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b # 3x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 4.0000],\n",
       "        [0.5000, 3.0000],\n",
       "        [2.0000, 3.6667]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a@b #   (3x3) * (3x2) = (3x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_19732\\1273687973.py:1: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  np.dot(a, b)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.       , 4.       ],\n",
       "       [0.5      , 3.       ],\n",
       "       [2.       , 3.6666667]], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a, b)   # (3x3) * (3x2) = (3x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,3) (3,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,3) (3,2) "
     ]
    }
   ],
   "source": [
    "np.multiply(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_19732\\483483825.py:1: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  np.multiply(a, [4,5,6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[4.0000, 0.0000, 0.0000],\n",
       "        [2.0000, 2.5000, 0.0000],\n",
       "        [1.3333, 1.6667, 2.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(a, [4,5,6]) # numpy broadcasting ( row(a) * row(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42) #This ensures that the results of any random operations (like torch.randint) will be reproducible.\n",
    "a = torch.tril(torch.ones(3, 3)) #lower triangular part of the matrix, setting all elements above the diagonal to zero.\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b  #This line performs matrix multiplication between a and b, storing the result in c. The @ operator is used for matrix multiplication in PyTorch.\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=') #The resulting matrix c will be a 3x2 matrix, where each element is a weighted sum of the corresponding elements in b, with the weights determined by the normalized rows of a.\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consider the following toy example:\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2 # batch, time step, channels or class\n",
    "x = torch.randn(B,T,C)  \n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line creates a random tensor x with shape (B, T, C), which is (4, 8, 2) in this case.\n",
    "# The torch.randn function generates a tensor with random values from a normal distribution (mean 0, standard deviation 1).\n",
    "# Result:\n",
    "# The resulting tensor x has:\n",
    "# 4 batches (or samples)\n",
    "# 8 time steps (or sequence length)\n",
    "# 2 channels (or classes)\n",
    "# This tensor can be used as input to various deep learning models, such as recurrent neural networks (RNNs), long short-term memory (LSTM) networks, or transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] # first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1808, -0.0700])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0] # time step or row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1808)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.3596, -0.9152],\n",
       "         [ 0.6258,  0.0255],\n",
       "         [ 0.9545,  0.0643],\n",
       "         [ 0.3612,  1.1679],\n",
       "         [-1.3499, -0.5102],\n",
       "         [ 0.2360, -0.2398],\n",
       "         [-0.9211,  1.5433]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.2858,  0.9651],\n",
       "         [-2.0371,  0.4931],\n",
       "         [ 1.4870,  0.5910],\n",
       "         [ 0.1260, -1.5627],\n",
       "         [-1.1601, -0.3348],\n",
       "         [ 0.4478, -0.8016],\n",
       "         [ 1.5236,  2.5086]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 1.0101,  0.1215],\n",
       "         [ 0.1584,  1.1340],\n",
       "         [-1.1539, -0.2984],\n",
       "         [-0.5075, -0.9239],\n",
       "         [ 0.5467, -1.4948],\n",
       "         [-1.2057,  0.5718],\n",
       "         [-0.5974, -0.6937]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.3514, -0.2759],\n",
       "         [-1.5108,  2.1048],\n",
       "         [ 2.7630, -1.7465],\n",
       "         [ 1.4516, -1.5103],\n",
       "         [ 0.8212, -0.2115],\n",
       "         [ 0.7789,  1.5333],\n",
       "         [ 1.6097, -0.4032]]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, :1] # first time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, :2] # 2nd time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, :3] # 3rd time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0894, -0.4926])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x[0, :2], axis=0) # over row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow = torch.zeros((B,T,C)) # bag of words (bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow[0,0] = torch.mean(x[0, :1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1808, -0.0700])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_flat = x.view(B*T,C) # to flat B,T, C to B*T, C\n",
    "x_back = x_flat.view(B, T, C) # to get back to B, T, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433],\n",
       "        [ 1.3488, -0.1396],\n",
       "        [ 0.2858,  0.9651],\n",
       "        [-2.0371,  0.4931],\n",
       "        [ 1.4870,  0.5910],\n",
       "        [ 0.1260, -1.5627],\n",
       "        [-1.1601, -0.3348],\n",
       "        [ 0.4478, -0.8016],\n",
       "        [ 1.5236,  2.5086],\n",
       "        [-0.6631, -0.2513],\n",
       "        [ 1.0101,  0.1215],\n",
       "        [ 0.1584,  1.1340],\n",
       "        [-1.1539, -0.2984],\n",
       "        [-0.5075, -0.9239],\n",
       "        [ 0.5467, -1.4948],\n",
       "        [-1.2057,  0.5718],\n",
       "        [-0.5974, -0.6937],\n",
       "        [ 1.6455, -0.8030],\n",
       "        [ 1.3514, -0.2759],\n",
       "        [-1.5108,  2.1048],\n",
       "        [ 2.7630, -1.7465],\n",
       "        [ 1.4516, -1.5103],\n",
       "        [ 0.8212, -0.2115],\n",
       "        [ 0.7789,  1.5333],\n",
       "        [ 1.6097, -0.4032]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.3596, -0.9152],\n",
       "         [ 0.6258,  0.0255],\n",
       "         [ 0.9545,  0.0643],\n",
       "         [ 0.3612,  1.1679],\n",
       "         [-1.3499, -0.5102],\n",
       "         [ 0.2360, -0.2398],\n",
       "         [-0.9211,  1.5433]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.2858,  0.9651],\n",
       "         [-2.0371,  0.4931],\n",
       "         [ 1.4870,  0.5910],\n",
       "         [ 0.1260, -1.5627],\n",
       "         [-1.1601, -0.3348],\n",
       "         [ 0.4478, -0.8016],\n",
       "         [ 1.5236,  2.5086]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 1.0101,  0.1215],\n",
       "         [ 0.1584,  1.1340],\n",
       "         [-1.1539, -0.2984],\n",
       "         [-0.5075, -0.9239],\n",
       "         [ 0.5467, -1.4948],\n",
       "         [-1.2057,  0.5718],\n",
       "         [-0.5974, -0.6937]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.3514, -0.2759],\n",
       "         [-1.5108,  2.1048],\n",
       "         [ 2.7630, -1.7465],\n",
       "         [ 1.4516, -1.5103],\n",
       "         [ 0.8212, -0.2115],\n",
       "         [ 0.7789,  1.5333],\n",
       "         [ 1.6097, -0.4032]]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6455, -0.8030],\n",
       "        [ 1.3514, -0.2759],\n",
       "        [-1.5108,  2.1048],\n",
       "        [ 2.7630, -1.7465],\n",
       "        [ 1.4516, -1.5103],\n",
       "        [ 0.8212, -0.2115],\n",
       "        [ 0.7789,  1.5333],\n",
       "        [ 1.6097, -0.4032]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xprev # for last batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.8173,  0.4127],\n",
       "         [-0.1342,  0.4395],\n",
       "         [ 0.2711,  0.4774],\n",
       "         [ 0.2421,  0.0694],\n",
       "         [ 0.0084,  0.0020],\n",
       "         [ 0.0712, -0.1128],\n",
       "         [ 0.2527,  0.2149]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 0.1735, -0.0649],\n",
       "         [ 0.1685,  0.3348],\n",
       "         [-0.1621,  0.1765],\n",
       "         [-0.2312, -0.0436],\n",
       "         [-0.1015, -0.2855],\n",
       "         [-0.2593, -0.1630],\n",
       "         [-0.3015, -0.2293]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.4985, -0.5395],\n",
       "         [ 0.4954,  0.3420],\n",
       "         [ 1.0623, -0.1802],\n",
       "         [ 1.1401, -0.4462],\n",
       "         [ 1.0870, -0.4071],\n",
       "         [ 1.0430, -0.1299],\n",
       "         [ 1.1138, -0.1641]]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 2: using matrix multiply for a weighted aggregation\n",
    "weight = torch.tril(torch.ones(T, T)) # time step T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.],\n",
       "        [7.],\n",
       "        [8.]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.sum(1, keepdim=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = weight / weight.sum(1, keepdim=True) # over column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow2 = weight @ x # (B, T, T) @ (B, T, C) ----> (B, T, C) \n",
    "# (T,T) @ (T,C) ----> (T,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.8173,  0.4127],\n",
       "         [-0.1342,  0.4395],\n",
       "         [ 0.2711,  0.4774],\n",
       "         [ 0.2421,  0.0694],\n",
       "         [ 0.0084,  0.0020],\n",
       "         [ 0.0712, -0.1128],\n",
       "         [ 0.2527,  0.2149]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 0.1735, -0.0649],\n",
       "         [ 0.1685,  0.3348],\n",
       "         [-0.1621,  0.1765],\n",
       "         [-0.2312, -0.0436],\n",
       "         [-0.1015, -0.2855],\n",
       "         [-0.2593, -0.1630],\n",
       "         [-0.3015, -0.2293]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.4985, -0.5395],\n",
       "         [ 0.4954,  0.3420],\n",
       "         [ 1.0623, -0.1802],\n",
       "         [ 1.1401, -0.4462],\n",
       "         [ 1.0870, -0.4071],\n",
       "         [ 1.0430, -0.1299],\n",
       "         [ 1.1138, -0.1641]]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.allclose(xbow, xbow2) is a PyTorch function that checks if two tensors, xbow and xbow2, are element-wise equal within a tolerance.\n",
    "# Parameters:\n",
    "# xbow and xbow2: The two tensors to compare.\n",
    "# Return Value:\n",
    "# The function returns a boolean tensor indicating whether the two input tensors are element-wise equal within the tolerance.\n",
    "# Tolerance:\n",
    "# By default, the tolerance is set to 1e-8, which means that the absolute difference between corresponding elements in the two tensors must be less than or equal to 1e-8 for them to be considered equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 3: use Softmax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "wei = wei.masked_fill(tril == 0, float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch.nn.functional' from 'd:\\\\a27_YEARS_OLD\\\\gpt\\\\venv\\\\Lib\\\\site-packages\\\\torch\\\\nn\\\\functional.py'>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "wei = F.softmax(wei, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow3 = wei @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.8173,  0.4127],\n",
       "         [-0.1342,  0.4395],\n",
       "         [ 0.2711,  0.4774],\n",
       "         [ 0.2421,  0.0694],\n",
       "         [ 0.0084,  0.0020],\n",
       "         [ 0.0712, -0.1128],\n",
       "         [ 0.2527,  0.2149]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 0.1735, -0.0649],\n",
       "         [ 0.1685,  0.3348],\n",
       "         [-0.1621,  0.1765],\n",
       "         [-0.2312, -0.0436],\n",
       "         [-0.1015, -0.2855],\n",
       "         [-0.2593, -0.1630],\n",
       "         [-0.3015, -0.2293]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.4985, -0.5395],\n",
       "         [ 0.4954,  0.3420],\n",
       "         [ 1.0623, -0.1802],\n",
       "         [ 1.1401, -0.4462],\n",
       "         [ 1.0870, -0.4071],\n",
       "         [ 1.0430, -0.1299],\n",
       "         [ 1.1138, -0.1641]]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 4: self-attention!\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700, -0.3596,  ..., -0.8016,  1.5236,  2.5086],\n",
       "         [-0.6631, -0.2513,  1.0101,  ...,  1.5333,  1.6097, -0.4032],\n",
       "         [-0.8345,  0.5978, -0.0514,  ..., -0.4370, -1.0012, -0.4094],\n",
       "         ...,\n",
       "         [-0.8961,  0.0662, -0.0563,  ...,  2.1382,  0.5114,  1.2191],\n",
       "         [ 0.1910, -0.3425,  1.7955,  ...,  0.3699, -0.5556, -0.3983],\n",
       "         [-0.5819, -0.2208,  0.0135,  ..., -1.9079, -0.5276,  1.0807]],\n",
       "\n",
       "        [[ 0.4562, -1.0917, -0.8207,  ...,  0.0512, -0.6576, -2.5729],\n",
       "         [ 0.0210,  1.0060, -1.2492,  ...,  0.7859, -1.1501,  1.3132],\n",
       "         [ 2.2007, -0.2195,  0.5427,  ..., -0.6445,  1.0834, -0.7995],\n",
       "         ...,\n",
       "         [ 0.3091,  1.1661, -2.1821,  ...,  0.6151,  0.6763,  0.6228],\n",
       "         [ 0.0943, -0.3156,  0.7850,  ..., -1.5735,  1.3876,  0.7251],\n",
       "         [ 0.6455, -0.3313, -1.0390,  ...,  0.0895, -0.3748, -0.4781]],\n",
       "\n",
       "        [[-0.6067,  1.8328,  0.2931,  ...,  1.0041,  0.8656,  0.1688],\n",
       "         [-0.2352, -0.2586,  0.0131,  ...,  0.6690,  0.7535, -0.5359],\n",
       "         [-1.0277,  0.5347, -0.7958,  ...,  1.0711,  0.4901, -0.4876],\n",
       "         ...,\n",
       "         [-0.6896, -0.7080, -0.3152,  ..., -2.0662, -1.1418, -0.1391],\n",
       "         [ 1.0827,  1.1522,  0.5198,  ...,  0.4970,  0.0585,  0.1033],\n",
       "         [ 0.0720,  1.1080,  0.7293,  ...,  0.3967, -0.9755,  0.5122]],\n",
       "\n",
       "        [[ 0.3330,  1.0995,  0.4034,  ...,  1.6634, -0.4718,  0.5857],\n",
       "         [-0.9579,  0.9435, -2.1992,  ..., -0.7296,  0.1653, -0.3390],\n",
       "         [ 1.5416,  1.0231,  1.3392,  ..., -0.0433, -0.2505, -0.7493],\n",
       "         ...,\n",
       "         [ 0.7450,  0.7170,  1.2668,  ...,  1.9359,  2.0350,  2.0187],\n",
       "         [ 0.0323, -0.6337,  0.2938,  ..., -0.3297, -0.0192,  0.9225],\n",
       "         [ 0.9187,  0.2998,  0.6106,  ...,  0.8282, -0.4826,  1.8330]]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see a single Head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=32, out_features=16, bias=False)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code defines a linear transformation layer (nn.Linear) named key with the following properties:\n",
    "# Input and Output Dimensions:\n",
    "# C: The input dimension, which is the number of channels or features in the input data.\n",
    "# head_size: The output dimension, which is set to 16. This represents the size of the key vector in the self-attention mechanism.\n",
    "# Bias Term:\n",
    "# bias=False: This argument specifies that the linear transformation layer should not include a bias term. In other words, the output of the layer will be computed as a simple matrix multiplication between the input and the weight matrix, without adding any bias term.\n",
    "# Purpose:\n",
    "# The key layer is likely part of a self-attention mechanism, where it is used to compute the key vectors that are used to compute attention weights. The output of this layer will be used to compute the attention weights, which are then used to compute the weighted sum of the value vectors.\n",
    "# Example:\n",
    "# Suppose C is 128 (the number of input channels), and head_size is 16. The key layer would be a linear transformation from 128-dimensional input vectors to 16-dimensional output vectors, without any bias term.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = key(x)   # (B, T, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code performs self-attention using a single attention head.\n",
    "# Linear Transformations:\n",
    "# The code defines three linear transformation layers:\n",
    "# key: Maps the input x to a key vector of size head_size (16).\n",
    "# query: Maps the input x to a query vector of size head_size (16).\n",
    "# value: Maps the input x to a value vector of size head_size (16).\n",
    "# Computing Key, Query, and Value:\n",
    "# The code applies the linear transformations to the input x:\n",
    "# k = key(x): Computes the key vector of shape (B, T, 16).\n",
    "# q = query(x): Computes the query vector of shape (B, T, 16).\n",
    "# Computing Attention Weights:\n",
    "# The code computes the attention weights by taking the dot product of the query and key vectors:\n",
    "# k.transpose(-2, -1): Transposes the key vector to shape (B, 16, T).\n",
    "# q @ k.transpose(-2, -1): Computes the dot product of the query and transposed key vectors, resulting in attention weights of shape (B, T, T).\n",
    "# The attention weights represent the importance of each time step in the input sequence relative to every other time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1965e-01, -3.0127e-01,  3.6293e-01,  1.1771e+00,  1.1385e+00,\n",
       "          -2.5543e-01,  1.4537e-01, -2.9437e-01, -7.0201e-01, -1.0308e+00,\n",
       "           7.4357e-01, -8.0984e-01, -6.6687e-01,  9.1233e-02, -6.0747e-03,\n",
       "           1.9833e-01],\n",
       "         [-5.4229e-01, -5.5581e-01, -7.6131e-02,  1.2929e+00,  8.6535e-01,\n",
       "          -1.1998e+00,  3.8781e-01,  1.9389e-01,  7.0235e-01, -8.2251e-01,\n",
       "           2.3484e-01, -8.4995e-01, -3.8126e-01, -2.9906e-01,  1.0242e-02,\n",
       "          -5.5449e-01],\n",
       "         [-3.7359e-01, -4.6781e-01, -2.1560e-01, -8.0344e-01, -3.7153e-01,\n",
       "          -5.4427e-01, -9.1455e-01, -5.5926e-02, -3.2903e-01, -2.1023e-01,\n",
       "           1.1665e-01, -1.7978e-01, -2.8196e-01, -3.3204e-01, -4.5963e-01,\n",
       "          -1.3255e-01],\n",
       "         [-3.1463e-01,  8.4460e-02, -1.2351e-01, -7.0577e-01, -1.8022e-01,\n",
       "           5.4922e-01, -8.9805e-01, -4.9384e-01,  6.7907e-01,  8.8270e-01,\n",
       "           4.9109e-01,  5.1903e-01,  9.0109e-01,  9.1255e-02, -1.9332e-01,\n",
       "          -6.7704e-01],\n",
       "         [ 2.3940e-02,  9.9822e-02, -1.8709e-01, -8.5960e-02, -4.8815e-01,\n",
       "          -1.6765e+00,  2.4126e-01,  7.3606e-01,  4.6080e-01, -8.7217e-01,\n",
       "          -4.2590e-01, -1.1347e+00, -1.0571e+00, -9.4006e-01,  1.3426e-01,\n",
       "          -1.5716e-02],\n",
       "         [-2.3618e-01, -7.8730e-01, -3.8019e-01,  5.8150e-01, -3.7222e-01,\n",
       "           1.2405e+00, -7.0045e-01, -1.4917e+00,  7.6784e-01,  3.5839e-01,\n",
       "           6.1200e-01, -7.9353e-02,  5.9827e-01,  2.6353e-01,  6.4905e-01,\n",
       "           7.0914e-02],\n",
       "         [-7.9413e-01, -1.6598e-01, -2.8096e-01, -1.0208e-01, -7.3521e-01,\n",
       "          -7.5183e-01, -1.2759e-01, -5.1134e-03,  3.3249e-01, -3.3738e-01,\n",
       "           1.6783e-01,  3.1048e-01,  2.2577e-01,  1.2434e-01,  4.6169e-01,\n",
       "           2.0156e-01],\n",
       "         [ 1.6513e-01, -1.5990e-01, -5.7168e-01, -3.9571e-01,  3.9301e-01,\n",
       "          -8.5665e-01,  3.3900e-01, -7.9771e-01,  2.2134e-01, -5.1612e-01,\n",
       "           1.8504e-01, -2.1048e-01,  3.7789e-01,  4.8222e-02, -4.7437e-01,\n",
       "          -5.0405e-02]],\n",
       "\n",
       "        [[-1.6977e-01, -1.5875e+00, -9.1855e-01,  6.6326e-02, -1.1497e+00,\n",
       "           2.7652e-01, -7.1052e-01, -6.0851e-01, -7.9616e-02, -1.3215e-01,\n",
       "           6.9567e-01,  6.7096e-01,  5.4679e-01,  7.6157e-01,  6.3947e-01,\n",
       "           5.8098e-01],\n",
       "         [-1.1435e-01, -3.5312e-01, -1.8434e-01,  5.2000e-01, -6.0603e-01,\n",
       "           6.3977e-01,  1.2789e-01, -8.0061e-01, -3.9588e-01,  9.8180e-01,\n",
       "          -2.7790e-01, -4.0351e-01, -6.6473e-01,  2.3659e-01,  2.4786e-01,\n",
       "           2.3966e-01],\n",
       "         [-6.3508e-01, -1.0090e+00,  4.4846e-01,  2.6102e-01,  3.0953e-01,\n",
       "           1.0269e+00, -5.0824e-01,  1.5112e-01,  4.9967e-01, -1.0242e+00,\n",
       "           3.3076e-02,  7.9948e-01,  4.7760e-01,  1.0383e-01,  2.8658e-01,\n",
       "           6.3477e-01],\n",
       "         [ 7.1183e-02,  5.7131e-01,  6.2270e-01,  2.4220e-01,  1.1163e+00,\n",
       "           5.2713e-01, -2.7616e-01, -2.8885e-01,  1.6921e-01,  1.0390e+00,\n",
       "          -1.2049e-01, -7.5153e-01,  2.8590e-01, -3.0348e-01, -3.1344e-02,\n",
       "          -6.0875e-01],\n",
       "         [-3.2904e-02,  5.3796e-01,  5.0853e-02,  1.1635e+00, -1.3198e-01,\n",
       "          -8.2809e-01,  3.2218e-01,  2.0548e-01, -1.3409e-01, -2.4342e-01,\n",
       "          -5.2483e-01, -1.0036e+00,  1.4676e-01,  6.1899e-02,  1.1584e-01,\n",
       "          -1.9803e-01],\n",
       "         [-1.5397e-01,  6.4264e-01, -1.2269e-01,  4.0754e-01,  7.2767e-02,\n",
       "          -2.1382e+00,  2.0803e+00,  1.0649e+00,  1.3110e-01, -1.7620e-01,\n",
       "          -1.1203e-02, -1.7259e+00, -7.9775e-01,  1.2679e+00, -6.2352e-03,\n",
       "          -2.9788e-02],\n",
       "         [ 7.5567e-01, -1.1675e-01, -7.9704e-01,  1.6243e-02,  8.6796e-01,\n",
       "          -2.0754e-01,  1.0132e+00, -8.4467e-01,  3.1207e-01,  3.1308e-01,\n",
       "          -4.0251e-01, -5.5028e-01, -1.1918e-02,  1.1328e-01, -1.2361e-01,\n",
       "           2.7873e-01],\n",
       "         [ 1.9565e-01,  1.5312e-01, -2.6387e-01, -9.0676e-01, -8.9970e-01,\n",
       "          -1.5432e-01,  2.9018e-01,  5.1112e-01,  3.9277e-01,  1.4502e-01,\n",
       "          -8.6059e-02,  1.0033e+00,  2.9766e-01, -4.0496e-02, -2.7407e-01,\n",
       "           6.2894e-01]],\n",
       "\n",
       "        [[ 2.1920e-01, -4.3338e-01, -1.7334e-02,  6.1086e-02, -5.0162e-01,\n",
       "          -9.1736e-01, -2.8565e-02, -2.9307e-01,  1.9116e-01,  4.5901e-01,\n",
       "          -6.4669e-01,  2.8410e-01,  7.1452e-01,  5.5001e-01,  7.2716e-02,\n",
       "           1.0264e+00],\n",
       "         [ 1.6208e-01,  4.7036e-01, -1.7571e-01, -1.4430e-01, -4.1618e-01,\n",
       "          -2.7120e-01,  1.7485e-01,  3.4478e-01,  2.0791e-03, -8.3833e-01,\n",
       "           4.8237e-01,  1.4978e-01,  2.6961e-01,  3.1957e-01,  3.1318e-01,\n",
       "           2.4300e-01],\n",
       "         [ 2.3199e-02,  9.1282e-01,  1.2309e-01,  4.3552e-01,  3.1683e-01,\n",
       "           5.4443e-01, -4.1182e-01, -3.9750e-01, -4.6773e-01,  1.4980e-01,\n",
       "          -7.6688e-04,  1.9398e-01, -5.9607e-02,  2.7678e-01,  3.8587e-01,\n",
       "           1.0099e-01],\n",
       "         [ 3.8775e-01, -7.5004e-01,  4.4353e-01,  2.0455e-01,  5.7050e-01,\n",
       "           5.2300e-01, -5.5296e-01,  3.4047e-01, -3.5511e-01, -6.9000e-01,\n",
       "           1.3859e-01, -6.1129e-01,  2.7986e-01, -1.0584e+00, -3.4378e-01,\n",
       "          -6.7254e-01],\n",
       "         [-7.4944e-01,  1.2011e+00,  4.7504e-01, -1.4175e+00, -1.1661e-01,\n",
       "          -2.0519e-01,  4.8880e-02, -5.6190e-01,  1.6865e-01, -5.8476e-01,\n",
       "           1.5643e-01,  2.0620e-01,  3.0129e-01,  3.0515e-01,  1.5822e-01,\n",
       "           1.3580e-01],\n",
       "         [ 3.2854e-03,  8.5792e-02, -3.7273e-01, -4.3263e-01,  2.7126e-01,\n",
       "           5.5295e-01, -3.3752e-01, -3.6228e-01,  3.7946e-01, -5.6956e-01,\n",
       "           3.5850e-01,  5.0297e-01,  8.3247e-01,  2.7065e-01,  2.3051e-01,\n",
       "          -3.7021e-01],\n",
       "         [ 2.6607e-01,  7.4628e-01,  9.7758e-01,  8.5964e-01,  7.2511e-01,\n",
       "          -6.1081e-01, -6.5677e-01, -5.0406e-02, -5.2642e-02,  5.8294e-01,\n",
       "          -4.5590e-02, -3.5460e-02,  9.0733e-01,  2.4781e-01, -1.8979e-01,\n",
       "          -9.3868e-01],\n",
       "         [-9.1529e-01, -9.2379e-01,  2.2234e-01, -3.1099e-01,  3.9580e-01,\n",
       "           5.2756e-01, -4.7417e-01, -2.0447e-01, -2.5679e-01,  3.5713e-01,\n",
       "           1.9908e-01,  7.3336e-02,  6.5161e-01, -2.3829e-01,  5.5460e-01,\n",
       "          -1.9587e-01]],\n",
       "\n",
       "        [[-1.5028e-01, -6.7611e-01, -9.4847e-02,  6.0556e-02, -1.2049e-01,\n",
       "           1.1210e-01,  5.8812e-01,  4.8340e-01, -4.8511e-01,  2.8539e-01,\n",
       "           1.1188e-01, -5.7574e-01,  1.4927e-01,  2.4169e-01, -1.1611e-01,\n",
       "          -1.2201e-01],\n",
       "         [ 3.1164e-01, -9.0459e-02, -2.8066e-01,  2.6897e-01,  6.4195e-01,\n",
       "          -6.5475e-01,  1.1037e+00, -4.5296e-01, -2.1339e-02,  1.6460e-01,\n",
       "           6.7715e-01,  2.3949e-01, -4.3220e-01,  9.4793e-01,  1.7489e-01,\n",
       "          -1.5304e-01],\n",
       "         [-7.9503e-01, -1.4741e+00,  1.1253e+00,  2.7440e-01, -1.4027e+00,\n",
       "           3.7211e-01, -3.9604e-01,  8.4127e-01,  3.5312e-01,  1.4552e-01,\n",
       "           4.2781e-01,  1.1326e+00,  1.9570e-01,  4.9587e-01,  1.9671e-01,\n",
       "           7.6903e-01],\n",
       "         [-3.3248e-01, -5.9558e-01, -2.0805e-01, -5.2000e-01, -1.0317e-01,\n",
       "          -1.0147e+00,  1.2277e-01,  5.6320e-01,  2.6245e-02, -2.8960e-01,\n",
       "           4.3904e-01,  2.1655e-01, -5.1625e-01,  6.9628e-01, -7.1387e-02,\n",
       "           5.5466e-01],\n",
       "         [ 7.1868e-01, -6.9756e-01,  1.7511e-01,  4.2946e-01, -6.4692e-02,\n",
       "           2.1727e-02,  1.6995e-01,  1.0254e-01,  1.7318e-02, -3.4716e-01,\n",
       "          -2.9683e-02,  2.2608e-01, -4.8018e-01, -3.1518e-01,  2.7052e-01,\n",
       "           2.4391e-01],\n",
       "         [-1.8101e-01,  9.1307e-01,  3.3671e-01,  2.0421e-01, -3.9466e-02,\n",
       "           4.7134e-01,  2.1301e-01,  8.5801e-01,  1.5041e-01, -3.7583e-01,\n",
       "          -1.2250e-01, -7.5942e-01,  6.6617e-02, -5.8663e-01, -1.5167e-02,\n",
       "           1.1934e-01],\n",
       "         [-3.1353e-02, -6.3727e-01, -5.9223e-01,  5.9708e-01,  2.5528e-01,\n",
       "          -1.6740e-01,  1.5375e-01, -1.4879e+00,  1.2765e-01,  1.8780e-01,\n",
       "           3.5408e-01, -4.7336e-02, -2.5101e-01,  9.1024e-01, -6.3272e-01,\n",
       "          -2.5878e-01],\n",
       "         [-1.2732e+00, -6.2869e-01,  5.6168e-02, -2.5592e-03, -7.3370e-01,\n",
       "          -2.7521e-01, -1.5650e-01,  3.9314e-01, -4.1830e-01, -1.7399e+00,\n",
       "           6.3731e-01, -6.3222e-01,  4.7992e-01,  1.8370e-01,  1.0338e+00,\n",
       "          -5.4454e-01]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = query(x) # (B, T, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-6.5674e-01,  2.8302e-02,  9.4470e-03, -6.9949e-01, -3.6043e-01,\n",
       "           8.3760e-01, -4.4455e-01,  1.2278e-01,  6.2761e-01, -6.2222e-01,\n",
       "           3.4833e-01,  2.4108e-01,  5.4092e-01, -2.6054e-01,  3.6119e-01,\n",
       "          -4.3574e-02],\n",
       "         [-3.9319e-01,  8.2196e-01, -7.0274e-01,  9.5429e-02, -1.2218e-01,\n",
       "          -1.5182e-01, -5.0242e-01, -4.6365e-01,  1.1758e-01,  1.4282e+00,\n",
       "          -5.8116e-01,  1.4008e-01,  9.6041e-01,  4.1002e-02, -6.2136e-01,\n",
       "          -6.3472e-01],\n",
       "         [ 2.1567e-01, -3.5065e-01,  2.1671e-03,  4.2317e-01, -2.2844e-01,\n",
       "          -7.3162e-02, -3.4118e-01,  9.6471e-01, -5.1775e-01,  9.2104e-02,\n",
       "          -5.0425e-01,  8.3885e-01,  6.1487e-01, -1.0894e-02, -5.5692e-01,\n",
       "           5.8197e-01],\n",
       "         [ 8.9999e-01, -1.2723e-01,  5.4581e-01,  4.2544e-01, -4.5128e-01,\n",
       "          -2.1242e-02,  1.7111e-01,  2.5990e-01, -9.9782e-01,  4.8897e-01,\n",
       "           1.7374e-01, -6.9986e-02, -3.1131e-01,  3.7479e-01, -1.8482e-01,\n",
       "          -6.3789e-01],\n",
       "         [ 3.3199e-02,  5.8858e-01, -4.4368e-01,  3.7748e-01, -6.8257e-01,\n",
       "          -2.7749e-01,  4.6726e-01, -1.2956e+00,  6.6032e-01,  1.6333e-01,\n",
       "          -1.7573e+00, -6.5818e-01, -2.3023e-01, -8.6169e-02, -5.9972e-03,\n",
       "           7.5729e-01],\n",
       "         [ 2.0985e-01,  4.3915e-02, -7.0198e-02,  7.2701e-02, -2.0124e-01,\n",
       "          -1.7539e+00,  1.0369e+00,  1.1635e-01,  2.9557e-01,  3.2307e-01,\n",
       "           5.0523e-01,  7.0110e-01, -2.8444e-01, -7.8443e-01,  4.7822e-01,\n",
       "          -5.1704e-01],\n",
       "         [ 6.1001e-01, -3.2841e-01, -8.5571e-01,  8.5427e-01,  7.8055e-01,\n",
       "          -4.0234e-01, -8.1832e-01, -5.5446e-02,  1.8732e-01,  2.7065e-01,\n",
       "          -7.0659e-01, -8.6369e-01,  6.9979e-01, -6.6958e-02,  2.5508e-01,\n",
       "           2.1492e-01],\n",
       "         [ 1.4591e-01,  1.3493e-01, -2.3353e-01, -4.1732e-02,  2.9277e-01,\n",
       "          -5.0801e-01,  1.1770e-01,  1.8610e-01,  1.4554e-01,  2.9240e-02,\n",
       "          -8.4698e-01,  6.1163e-01,  1.2445e+00,  1.9087e-01,  3.6944e-01,\n",
       "          -2.7448e-03]],\n",
       "\n",
       "        [[ 1.1104e+00, -8.7192e-01,  7.0978e-01,  3.6331e-01,  2.0670e-01,\n",
       "          -3.5486e-02, -3.1695e-02,  6.9234e-01, -4.1590e-01, -1.6547e+00,\n",
       "           4.3214e-01, -1.1557e+00,  7.1400e-02, -6.7660e-01,  6.0415e-01,\n",
       "          -5.9200e-01],\n",
       "         [ 3.2561e-01,  5.7866e-01,  5.4575e-01, -7.2274e-01,  1.2343e+00,\n",
       "          -1.5586e-01,  6.8699e-01, -6.3906e-01,  6.1569e-01,  2.1342e-01,\n",
       "          -9.3616e-01,  2.7811e-01,  9.5776e-01,  1.7266e-01, -1.6889e-01,\n",
       "          -1.7047e-02],\n",
       "         [-1.5634e-02, -5.4639e-01,  3.0958e-01,  3.5532e-01,  5.9885e-01,\n",
       "          -8.2791e-01, -5.9326e-01,  7.3282e-01, -4.5197e-01, -8.4692e-01,\n",
       "           5.1515e-01, -1.0304e-02, -2.4767e-01, -6.7420e-02,  1.9622e-03,\n",
       "          -8.3188e-01],\n",
       "         [-2.4959e-01,  2.7492e-01,  2.6894e-01, -3.6563e-01, -3.2585e-01,\n",
       "           3.7158e-01, -8.7898e-01,  1.5132e-01,  3.0180e-02,  3.2213e-01,\n",
       "           3.9398e-01,  6.9950e-01,  9.7176e-02,  8.0347e-02, -1.1910e-02,\n",
       "           3.9823e-01],\n",
       "         [ 3.9181e-01,  5.7756e-01,  1.3630e-01, -3.3129e-01,  3.4955e-01,\n",
       "           3.3893e-01,  2.8573e-01, -3.3917e-01,  6.8701e-01,  3.2722e-01,\n",
       "          -1.0067e+00, -5.3265e-01,  1.0750e+00,  2.7662e-01, -5.8393e-01,\n",
       "          -3.2861e-01],\n",
       "         [ 6.6613e-01,  2.1817e+00, -4.7026e-01,  5.5768e-02, -8.0701e-01,\n",
       "           6.1819e-01,  1.8163e-01, -5.4206e-01,  8.6598e-01,  9.1274e-01,\n",
       "          -1.1465e+00,  1.2842e+00,  2.2156e+00,  8.1063e-01, -1.0830e+00,\n",
       "          -1.6162e-01],\n",
       "         [-5.6865e-01,  4.0198e-01, -5.5940e-01,  2.4041e-01,  2.5784e-02,\n",
       "          -4.5127e-01,  2.0618e-01, -1.1354e-01, -5.3368e-01,  9.9677e-01,\n",
       "          -3.4785e-01,  3.3627e-02,  1.3022e-01, -3.5643e-01,  4.5948e-01,\n",
       "          -3.3823e-01],\n",
       "         [ 5.9567e-01,  2.7697e-01, -5.3694e-01,  3.8806e-01, -5.2068e-01,\n",
       "           6.3736e-02, -4.6341e-01,  1.6976e-01, -6.2182e-01, -8.5360e-01,\n",
       "           1.5969e-02, -4.1913e-01,  7.5529e-01,  3.6444e-01,  4.0385e-01,\n",
       "          -1.9791e-01]],\n",
       "\n",
       "        [[ 1.3326e+00,  1.0350e+00, -1.3503e-02, -9.2348e-01,  1.0694e+00,\n",
       "          -1.4107e-01,  4.7608e-01, -2.5034e-01, -2.9667e-02, -4.9094e-01,\n",
       "          -6.6426e-01,  9.3041e-02,  1.4563e+00,  1.4807e-01, -6.1347e-01,\n",
       "          -1.0926e+00],\n",
       "         [ 5.4338e-01, -1.9188e-01, -5.3040e-01,  6.8131e-01,  6.2352e-02,\n",
       "          -2.8209e-01, -1.6728e-02,  5.4435e-01, -3.0124e-01, -1.1855e-01,\n",
       "          -1.8416e-01, -4.8132e-01, -2.1184e-01,  2.4121e-01,  2.1798e-02,\n",
       "          -6.9178e-02],\n",
       "         [-3.3528e-01, -5.6466e-01,  6.6484e-01, -1.5190e-01,  3.6304e-01,\n",
       "           6.2404e-01, -2.4197e-01,  1.1305e+00,  1.7005e-01,  3.6276e-01,\n",
       "           8.0700e-01, -1.0924e-01,  1.9538e-01, -4.2642e-01, -6.4841e-01,\n",
       "          -2.0725e-01],\n",
       "         [-1.0337e-01,  8.0347e-02, -3.1804e-01, -1.0417e+00,  6.4425e-02,\n",
       "          -4.2446e-01,  4.8210e-01,  2.6664e-01, -5.0266e-01, -1.4787e+00,\n",
       "           1.0776e+00,  2.1790e-01, -8.7924e-01,  1.0318e-01,  1.1044e-01,\n",
       "          -8.6890e-01],\n",
       "         [ 7.3975e-01, -5.6316e-01,  6.8825e-01,  6.8188e-01,  9.2013e-01,\n",
       "          -6.6580e-01, -2.3015e-01,  3.4094e-01,  4.4395e-01,  6.7518e-01,\n",
       "           2.6042e-01,  1.4252e+00,  7.6539e-01,  2.5805e-01, -7.9161e-01,\n",
       "           7.3077e-01],\n",
       "         [ 4.9907e-02, -4.8685e-01,  2.1095e-01, -3.5810e-01,  1.2314e-01,\n",
       "           1.5951e-01,  1.7245e-01,  2.8349e-01, -2.1648e-01, -5.0059e-01,\n",
       "          -2.0210e-01,  2.4838e-01,  1.3610e-02,  1.0566e+00,  2.7065e-01,\n",
       "          -4.7702e-01],\n",
       "         [-6.4012e-01,  4.7867e-02, -2.7659e-02, -5.3705e-01,  4.5048e-01,\n",
       "           2.2384e-01, -1.1379e+00,  5.9782e-01,  1.0890e-02, -4.5584e-01,\n",
       "           7.9715e-01,  3.0061e-01,  7.8801e-01, -2.9773e-01, -1.7181e-01,\n",
       "          -7.1184e-01],\n",
       "         [ 4.1348e-02, -6.6965e-01, -4.0473e-01, -8.1760e-01, -1.4332e-01,\n",
       "          -2.2694e-01,  8.5180e-02,  3.4696e-01,  2.9030e-02,  2.2824e-01,\n",
       "           4.9848e-01,  3.6049e-01, -4.2176e-01, -5.3471e-01, -5.0211e-02,\n",
       "           1.8603e-01]],\n",
       "\n",
       "        [[ 6.2212e-04,  3.1138e-01, -7.1241e-01, -5.4445e-01,  8.2328e-01,\n",
       "          -1.6868e-01,  2.2658e-01,  4.8862e-01, -7.2207e-01,  3.6705e-01,\n",
       "          -1.3507e-01,  3.5477e-02, -4.4308e-01, -4.5602e-01, -9.0744e-01,\n",
       "          -2.2787e-01],\n",
       "         [-8.5366e-01, -1.1014e-02, -1.6077e-01,  1.7788e-03, -1.3390e-01,\n",
       "          -4.7289e-01, -2.1686e-01,  4.3677e-01,  8.0428e-01,  1.0344e+00,\n",
       "           8.8352e-03,  2.7911e-01, -7.6171e-02, -7.9940e-01,  4.4846e-01,\n",
       "           7.0971e-01],\n",
       "         [ 1.4088e+00, -4.4377e-02, -2.5436e-03,  1.2366e-01,  5.7979e-01,\n",
       "          -7.1957e-01, -5.0969e-01, -8.0928e-01, -8.9076e-02, -7.4968e-02,\n",
       "          -8.5395e-01, -1.5098e+00, -1.1381e+00, -6.0501e-02,  1.5464e-01,\n",
       "           3.2477e-01],\n",
       "         [ 1.9741e-01, -2.5031e-01, -1.2182e-01,  4.9976e-01,  2.4592e-01,\n",
       "           6.9912e-01, -4.1537e-01, -1.3993e+00,  5.9324e-01,  7.7563e-02,\n",
       "          -1.0144e+00, -8.3186e-01,  1.7011e-01, -3.2685e-01,  6.3889e-01,\n",
       "          -9.1289e-03],\n",
       "         [-1.1387e-02,  8.6315e-01,  2.5427e-01, -3.2685e-02, -1.1675e-02,\n",
       "          -6.4872e-01,  1.3967e-01, -1.2100e-01, -3.6965e-01, -3.9830e-01,\n",
       "           2.0917e-01, -4.2211e-02,  3.5471e-01, -1.4781e-02,  1.0395e-01,\n",
       "          -8.2862e-01],\n",
       "         [-3.7612e-01, -7.3518e-02, -1.1904e+00,  7.2211e-01,  2.6136e-01,\n",
       "          -3.6523e-01,  1.0752e+00, -4.8674e-01, -4.3567e-01,  1.3338e-01,\n",
       "           6.0010e-01, -3.8806e-01, -1.5267e+00, -3.4049e-01,  3.2029e-01,\n",
       "          -3.5348e-01],\n",
       "         [-3.8176e-01,  7.8970e-01,  8.1802e-01,  8.8146e-01,  7.0618e-01,\n",
       "          -6.2861e-01, -6.7371e-01, -1.7663e-01,  5.2108e-01,  6.6437e-01,\n",
       "          -8.8697e-01,  5.0958e-02,  6.5746e-01, -6.3669e-01, -8.9697e-02,\n",
       "           3.2022e-01],\n",
       "         [-3.0550e-01,  8.9354e-02, -2.3808e-01,  1.0563e+00,  3.4164e-01,\n",
       "          -9.2939e-01,  8.5246e-01,  2.3477e-02,  1.6643e-01, -1.2088e+00,\n",
       "          -2.5446e-01,  6.6724e-01, -1.5612e-01, -1.7337e-01,  1.2187e-01,\n",
       "           2.0050e-01]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)   # k > (B, T, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.7629e+00, -1.3011e+00,  5.6516e-01,  2.1616e+00, -1.0674e+00,\n",
       "           1.9632e+00,  1.0765e+00, -4.5295e-01],\n",
       "         [-3.3334e+00, -1.6556e+00,  1.0405e-01,  3.3782e+00, -2.1825e+00,\n",
       "           1.0415e+00, -5.5714e-02,  2.9273e-01],\n",
       "         [-1.0226e+00, -1.2606e+00,  7.6228e-02, -3.8125e-01, -9.8430e-01,\n",
       "          -1.4303e+00,  7.4921e-02, -9.5465e-01],\n",
       "         [ 7.8359e-01, -8.0143e-01, -3.3680e-01, -8.4963e-01, -5.6023e-01,\n",
       "          -1.1701e+00, -1.2927e+00, -1.0260e+00],\n",
       "         [-1.2566e+00,  1.8719e-02, -7.8797e-01, -1.3204e+00,  2.0363e+00,\n",
       "           8.6381e-01,  3.7188e-01,  9.2577e-01],\n",
       "         [-3.1262e-01,  2.4152e+00, -1.1058e-01, -9.9305e-01,  3.3449e+00,\n",
       "          -2.5229e+00,  1.4187e+00,  1.2196e+00],\n",
       "         [ 1.0876e+00,  1.9652e+00, -2.6213e-01, -3.1579e-01,  6.0905e-01,\n",
       "           1.2616e+00, -5.4841e-01,  8.0485e-01],\n",
       "         [-1.8044e+00, -4.1260e-01, -8.3061e-01,  5.8985e-01, -7.9869e-01,\n",
       "          -5.8560e-01,  6.4332e-01,  6.3028e-01]],\n",
       "\n",
       "        [[-7.3529e-01, -1.7807e+00,  1.0745e+00, -2.7429e-01,  1.6347e+00,\n",
       "           1.4177e+00, -5.5213e-01, -2.3580e+00],\n",
       "         [-3.0892e+00, -1.4943e+00, -2.6167e-01,  2.2760e+00, -2.4364e-01,\n",
       "           1.6198e-01,  2.5783e+00,  3.9591e-01],\n",
       "         [-5.0206e-01, -2.0745e+00,  5.3785e-01, -4.0494e-01,  8.3292e-01,\n",
       "           1.3570e+00, -1.5621e+00, -1.6490e+00],\n",
       "         [ 1.3810e+00, -1.4713e-01,  1.2181e+00, -2.2266e-01, -1.8247e+00,\n",
       "          -3.7044e+00, -2.1321e+00,  1.3178e+00],\n",
       "         [-2.3568e+00, -4.6170e-01, -8.8196e-01,  2.3700e+00,  6.7828e-01,\n",
       "           1.6262e-01,  1.9379e+00,  1.0397e-01],\n",
       "         [-9.2435e-01, -6.2351e-01, -1.3938e+00,  1.3336e+00, -8.9727e-03,\n",
       "          -3.1789e+00,  9.0259e-01,  3.6256e+00],\n",
       "         [-6.5522e-01,  1.0991e+00, -2.1399e+00,  9.6468e-01,  9.9463e-01,\n",
       "           9.3899e-01,  4.6799e-01, -3.5870e-01],\n",
       "         [ 1.5463e+00, -4.9438e-01, -1.4180e-02, -9.7428e-01,  1.3779e+00,\n",
       "           7.8650e-03, -5.3590e-01, -4.5531e-01]],\n",
       "\n",
       "        [[-3.7898e-01,  5.1592e-01,  3.0332e-01,  1.1303e+00,  2.0511e+00,\n",
       "           2.2323e+00,  3.1239e+00, -1.2231e+00],\n",
       "         [ 1.0377e-01,  1.7584e-01, -1.6369e-01,  5.2328e-01, -2.2172e+00,\n",
       "          -8.7770e-01,  1.7020e-01, -1.0842e+00],\n",
       "         [-1.6373e+00, -6.5557e-01, -8.5031e-01,  2.3457e+00, -9.9497e-01,\n",
       "          -4.9228e-02,  5.5157e-01,  1.5285e+00],\n",
       "         [-2.7155e+00,  1.9022e+00, -8.4620e-01,  5.9058e-01,  2.1122e+00,\n",
       "           8.8971e-01, -2.0679e+00, -7.4249e-01],\n",
       "         [ 2.5044e+00, -4.9691e-01, -2.6300e-01, -1.6288e-01, -1.7459e+00,\n",
       "           8.6298e-02,  2.7739e+00, -2.4952e-02],\n",
       "         [-4.8634e-02,  4.9620e-01, -2.0859e-01, -8.4632e-02,  3.6811e-01,\n",
       "           7.8713e-01, -1.9678e-01,  4.1090e-01],\n",
       "         [-1.7485e+00,  4.6233e-01,  3.8657e-03,  2.1114e+00,  1.2731e+00,\n",
       "           2.1582e+00,  1.3125e+00,  2.0600e+00],\n",
       "         [-8.5500e-02, -1.5413e-02, -1.3915e+00,  6.3086e-02, -2.4530e-01,\n",
       "          -2.0677e-01, -2.2102e+00,  4.4531e-01]],\n",
       "\n",
       "        [[ 4.5165e-01,  3.2148e-01, -3.1926e+00,  3.0765e-01, -6.1612e-01,\n",
       "           2.5626e-01, -2.9891e-01, -2.1917e+00],\n",
       "         [-4.0009e-01, -9.6205e-01,  1.9568e+00,  6.6612e-01, -3.2630e-01,\n",
       "           2.6258e-01, -1.3973e+00, -8.9450e-01],\n",
       "         [-4.6199e-01,  5.8600e-01, -4.6738e+00, -3.2178e-01,  1.2684e+00,\n",
       "          -1.7402e-01,  1.2461e+00, -2.2283e+00],\n",
       "         [-7.1746e-01, -1.0279e+00, -2.0509e+00, -2.7234e+00,  3.1231e-01,\n",
       "          -1.6416e-01,  1.5162e+00, -7.7670e-01],\n",
       "         [-4.0388e-01,  5.1597e-01, -2.0697e+00, -4.0982e-01, -8.0534e-01,\n",
       "           5.2210e-01, -4.1242e-01,  1.3377e+00],\n",
       "         [ 8.2322e-01,  3.0237e+00, -3.0655e+00,  7.0404e-01,  6.7207e-01,\n",
       "          -4.6692e-01,  2.3746e+00,  3.1181e-01],\n",
       "         [-1.4141e+00, -1.4241e+00, -8.0387e-01, -1.7450e+00, -7.4035e-01,\n",
       "           9.8188e-01, -9.0056e-01, -2.3158e+00],\n",
       "         [-5.0277e-01,  1.6844e+00, -4.1847e-01,  1.0239e+00,  1.0275e+00,\n",
       "           1.3980e-01,  4.8822e-01,  1.5573e+00]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "tril = torch.tril(torch.ones(T, T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "         [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "         [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1687, 0.8313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2477, 0.0514, 0.7008, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4410, 0.0957, 0.3747, 0.0887, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0069, 0.0456, 0.0300, 0.7748, 0.1427, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0660, 0.0892, 0.0413, 0.6316, 0.1649, 0.0069, 0.0000, 0.0000],\n",
       "         [0.0396, 0.2288, 0.0090, 0.2000, 0.2061, 0.1949, 0.1217, 0.0000],\n",
       "         [0.3650, 0.0474, 0.0767, 0.0293, 0.3084, 0.0784, 0.0455, 0.0493]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4820, 0.5180, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1705, 0.4550, 0.3745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0074, 0.7444, 0.0477, 0.2005, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.8359, 0.0416, 0.0525, 0.0580, 0.0119, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1195, 0.2061, 0.1019, 0.1153, 0.1814, 0.2758, 0.0000, 0.0000],\n",
       "         [0.0065, 0.0589, 0.0372, 0.3063, 0.1325, 0.3209, 0.1378, 0.0000],\n",
       "         [0.1416, 0.1519, 0.0384, 0.1643, 0.1207, 0.1254, 0.0169, 0.2408]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6369, 0.3631, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2586, 0.7376, 0.0038, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4692, 0.3440, 0.1237, 0.0631, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1865, 0.4680, 0.0353, 0.1854, 0.1248, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0828, 0.7479, 0.0017, 0.0735, 0.0712, 0.0228, 0.0000, 0.0000],\n",
       "         [0.0522, 0.0517, 0.0961, 0.0375, 0.1024, 0.5730, 0.0872, 0.0000],\n",
       "         [0.0306, 0.2728, 0.0333, 0.1409, 0.1414, 0.0582, 0.0825, 0.2402]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = value(x)\n",
    "out = wei @ v\n",
    "#out = wei @ x\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0449)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0700)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0700)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8000, -1.6000,  2.4000, -1.6000,  4.0000])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1) # gets too peaky, converges to one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x29496d6a690>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=100\n",
    "eps=1e-5\n",
    "momentum=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = torch.ones(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.zeros(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmean = x.mean(1, keepdim=True) # batch mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0409],\n",
       "        [ 0.0701],\n",
       "        [-0.2667],\n",
       "        [-0.0407],\n",
       "        [-0.1346],\n",
       "        [-0.0208],\n",
       "        [-0.1020],\n",
       "        [-0.0780],\n",
       "        [ 0.0502],\n",
       "        [ 0.1726],\n",
       "        [-0.1185],\n",
       "        [ 0.0410],\n",
       "        [-0.0751],\n",
       "        [-0.0210],\n",
       "        [ 0.2044],\n",
       "        [ 0.0298],\n",
       "        [ 0.0182],\n",
       "        [ 0.0702],\n",
       "        [-0.0514],\n",
       "        [-0.2094],\n",
       "        [ 0.0603],\n",
       "        [-0.0183],\n",
       "        [ 0.2128],\n",
       "        [-0.0231],\n",
       "        [ 0.0253],\n",
       "        [ 0.0168],\n",
       "        [ 0.0518],\n",
       "        [-0.0567],\n",
       "        [ 0.2676],\n",
       "        [ 0.1119],\n",
       "        [ 0.0148],\n",
       "        [-0.1235]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvar = x.var(1, keepdim=True) # batch variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0974],\n",
       "        [1.1914],\n",
       "        [0.8626],\n",
       "        [1.0505],\n",
       "        [1.2440],\n",
       "        [0.9635],\n",
       "        [1.2625],\n",
       "        [0.9310],\n",
       "        [1.2030],\n",
       "        [0.9291],\n",
       "        [0.9190],\n",
       "        [1.1037],\n",
       "        [0.8750],\n",
       "        [1.0331],\n",
       "        [0.9004],\n",
       "        [0.8774],\n",
       "        [0.9265],\n",
       "        [0.7519],\n",
       "        [0.9805],\n",
       "        [0.8804],\n",
       "        [1.1778],\n",
       "        [0.8729],\n",
       "        [0.9903],\n",
       "        [0.7439],\n",
       "        [0.9101],\n",
       "        [0.9875],\n",
       "        [0.9775],\n",
       "        [0.7879],\n",
       "        [1.2659],\n",
       "        [1.1954],\n",
       "        [1.1272],\n",
       "        [1.0917]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat = (x - xmean) / torch.sqrt(xvar + eps) # normalize to unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1335, -0.1059, -0.3824,  ..., -1.3422, -0.1971,  0.8795],\n",
       "        [-0.0353, -0.7439, -0.3371,  ..., -0.6276, -0.4846,  0.4556],\n",
       "        [ 0.3069, -1.5010,  1.4898,  ..., -0.6819,  0.9993,  0.8382],\n",
       "        ...,\n",
       "        [-1.6080, -1.6324, -0.7634,  ..., -0.9847,  0.0039, -0.8610],\n",
       "        [-0.2273,  0.0066, -0.2763,  ..., -0.8705, -1.2442, -0.7531],\n",
       "        [ 0.3054, -0.1505, -0.3809,  ..., -1.4962, -0.7711, -1.0681]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = gamma * xhat + beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1335, -0.1059, -0.3824,  ..., -1.3422, -0.1971,  0.8795],\n",
       "        [-0.0353, -0.7439, -0.3371,  ..., -0.6276, -0.4846,  0.4556],\n",
       "        [ 0.3069, -1.5010,  1.4898,  ..., -0.6819,  0.9993,  0.8382],\n",
       "        ...,\n",
       "        [-1.6080, -1.6324, -0.7634,  ..., -0.9847,  0.0039, -0.8610],\n",
       "        [-0.2273,  0.0066, -0.2763,  ..., -0.8705, -1.2442, -0.7531],\n",
       "        [ 0.3054, -0.1505, -0.3809,  ..., -1.4962, -0.7711, -1.0681]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LayerNorm1d: # (used to be BatchNorm1d)\n",
    "\n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    xmean = x.mean(1, keepdim=True) # batch mean\n",
    "    xvar = x.var(1, keepdim=True) # batch variance\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    return self.out\n",
    "\n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100)\n",
    "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
    "x = module(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1469), tensor(0.8803))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0].mean(), x[:,0].std() # mean,std of one feature across all batch inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.5367e-09), tensor(1.0000))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# French to English translation example:\n",
    "\n",
    "# <--------- ENCODE ------------------><--------------- DECODE ----------------->\n",
    "# les rseaux de neurones sont gniaux! <START> neural networks are awesome!<END>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.208052 M parameters\n",
      "step 0: train loss 4.0616, val loss 4.0581\n",
      "step 50: train loss 2.6709, val loss 2.6608\n",
      "step 100: train loss 2.3911, val loss 2.5283\n",
      "step 150: train loss 2.2744, val loss 2.4777\n",
      "step 200: train loss 2.1685, val loss 2.4533\n",
      "step 250: train loss 2.0550, val loss 2.4504\n",
      "step 300: train loss 1.9358, val loss 2.4177\n",
      "step 350: train loss 1.8008, val loss 2.4057\n",
      "step 400: train loss 1.6750, val loss 2.3769\n",
      "step 450: train loss 1.5204, val loss 2.4588\n",
      "step 499: train loss 1.3874, val loss 2.5279\n",
      "\n",
      "Al:\n",
      "Wou, you munto :away pricin s as Le e deridevenkcon waing to tund\n",
      "wicte us, o remit o an to thad aren.\n",
      "Agoich Car Caibuity pealenkin:\n",
      "Re tolld a!\n",
      "Hay wake coud wockned spear oovicece.\n",
      "\n",
      "Yvenk Citizen:\n",
      "Wibute iuns baris ant to thaffa\n",
      "suluir is  in ta ayRiu us asto\n",
      "ENMENENIUS:\n",
      "IUS:\n",
      "Whte spromid:\n",
      "Le t llened sore?\n",
      "We Citizen:\n",
      "Iknot, aurespree ing ond ofthth ditir hie? dik. : sunor Yow shesunat the fohe fourser ciens as unfthats havis or\n",
      "vintr to thene cone er aon the? to the\n",
      "hunth to bur sis we ares ay heatose!\n",
      "\n",
      "Allllvend.\n",
      "\n",
      "Fit Citizen:\n",
      "w'st brevenThat imy e, the sproun hatevelir ing thufth th woulur the paris tr? klll'ts; you. Bay. I\n",
      "\n",
      "IUSesecout ENNMENENIUS:\n",
      "First Citigus Cousither ar ciunvis orvicen ar idon thaido the rerieveng the tod\n",
      "ro thad dint onke w'thel revem\n",
      "ge thod therot cis tha dind\n",
      "to ar bunce ian\n",
      "ccousar ais arffesty,\n",
      "Sufiitsiusth asr uto sher undotiviony iustrbus to mus ra ounthe war tar cce aulaviunsurn hemy inen is ay hous acour nto \n",
      "May coun atacciaccemas hi don the the alnd.\n",
      "\n",
      "Whout CitayWis is undoevi.\n",
      "First CLen:\n",
      "Our sirf tirpeicen:\n",
      "Whicour ante afoulicens im\n",
      "MENENhS: now'e, t, thay yountsur acius us buntr imens: to le aray his as apereves abrmave dontr natate;\n",
      "hatp aricus on in\n",
      "Whis youser istoule!\n",
      "\n",
      "First wor vir hethee aveUprot par ary spad.\n",
      "\n",
      "MENENENI MENIUS:Vlly, you,\n",
      "First worstay Citizen:\n",
      "I his herenee youneved forsthe citu.\n",
      "\n",
      "Firs Citizen:\n",
      "We IUSuston hannt herimus Ror muser ffacitr instry, hent cat hate acccimy cepeake sprakict insto wath ataus whea\n",
      "andtrice ond redof the countaiiw\n",
      "wh a the andone ch suntom,\n",
      "?\n",
      "Why Couitiz?YouryNIUSghe wery you\n",
      "Secougatululy and hes, coun esusur mus in imust in to inaw wituyou.\n",
      "First Citizen:\n",
      "Ar youll:\n",
      "Nhe at't ma cmy ist inven antartaty do.\n",
      "\n",
      "Fither, itizen:\n",
      "NENhy, moend mid toondes, oncccat!\n",
      "\n",
      "AgHianct cund hary westhe paknot citurery? wheuth, Cavenus itonce ar cceviar ans thesar tabs? Ro the\n",
      " Cofe Citizen:\n",
      "Whe uno mat, helve youwhy he taclme hantr, atiens\n",
      "he cou's aventhour thaur parfustice has as halce ve\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 500\n",
    "eval_interval = 50\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 100\n",
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "with open('data/small_input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "# super simple bigram model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
